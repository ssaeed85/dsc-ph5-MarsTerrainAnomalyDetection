{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6706f64a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T05:30:46.363958Z",
     "start_time": "2022-05-29T05:30:46.348955Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e38ef2bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T05:30:47.109385Z",
     "start_time": "2022-05-29T05:30:46.364958Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b73f9593",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T05:30:49.496825Z",
     "start_time": "2022-05-29T05:30:47.110385Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models, optimizers, losses\n",
    "from tensorflow.keras.callbacks import EarlyStopping, CSVLogger, ModelCheckpoint\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "seed = 42\n",
    "\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "import seaborn as sns\n",
    "\n",
    "tf_chkpt_path = 'tf_TransferLearning_8Classes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9bb20ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T05:30:49.512839Z",
     "start_time": "2022-05-29T05:30:49.498826Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.helperFunctions import display_model_trainTestGraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8dde351",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T05:30:49.528031Z",
     "start_time": "2022-05-29T05:30:49.513840Z"
    }
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b166097",
   "metadata": {},
   "source": [
    "# Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14301be3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T08:02:04.740933Z",
     "start_time": "2022-05-29T08:02:03.462113Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 48979 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "# Normalizing data for 8 bit\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'images/train/',\n",
    "    target_size = (227,227),\n",
    "    batch_size=2,\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c458bee7",
   "metadata": {},
   "source": [
    "# Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1f197449",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T08:02:05.137946Z",
     "start_time": "2022-05-29T08:02:04.741934Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14175 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "# Normalizing data for 8 bit\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    'images/val/',\n",
    "    target_size = (227,227),\n",
    "    batch_size=10,\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b36cfb",
   "metadata": {},
   "source": [
    "# Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b5008dc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T08:02:05.200607Z",
     "start_time": "2022-05-29T08:02:05.138946Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1793 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "# Normalizing data for 8 bit\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'images/test/',\n",
    "    target_size = (227,227),\n",
    "    batch_size=1,\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2443eadf",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "81641107",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T08:02:05.216621Z",
     "start_time": "2022-05-29T08:02:05.201608Z"
    }
   },
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', \n",
    "                           min_delta=1e-8,\n",
    "                           verbose=1,\n",
    "                           patience = 20,\n",
    "                           restore_best_weights=True,\n",
    "                           mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "53df31ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T08:02:05.232384Z",
     "start_time": "2022-05-29T08:02:05.217625Z"
    }
   },
   "outputs": [],
   "source": [
    "csv_logger = CSVLogger('Logger.log', separator=',', append=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "19098e0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T08:02:05.248399Z",
     "start_time": "2022-05-29T08:02:05.233385Z"
    }
   },
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    elif epoch >100:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.01)\n",
    "    \n",
    "    \n",
    "lr_schd_cb = tf.keras.callbacks.LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9b03691c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T08:02:05.264413Z",
     "start_time": "2022-05-29T08:02:05.249400Z"
    }
   },
   "outputs": [],
   "source": [
    "best_model = ModelCheckpoint(tf_chkpt_path+'_best_model.hdf5', \n",
    "                             monitor='val_loss', \n",
    "                             verbose=1,\n",
    "                             save_best_only=True, \n",
    "                             mode='min', \n",
    "                             save_freq='epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969e97da",
   "metadata": {},
   "source": [
    "# VGG 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "048b6e95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T08:02:05.501065Z",
     "start_time": "2022-05-29T08:02:05.265415Z"
    }
   },
   "outputs": [],
   "source": [
    "vgg = tf.keras.applications.vgg16.VGG16(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    classes=7,\n",
    "    classifier_activation='softmax',\n",
    "    input_shape=(227,227,3),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "868a32b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T08:02:05.564435Z",
     "start_time": "2022-05-29T08:02:05.505078Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 200712    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,915,400\n",
      "Trainable params: 14,915,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  vgg,\n",
    "  layers.Flatten(),\n",
    "    layers.Dense(8, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.00001),\n",
    "              loss=losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy',\n",
    "#                        Precision(),\n",
    "#                        Recall()\n",
    "                       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c0b11524",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T16:12:13.747391Z",
     "start_time": "2022-05-29T08:02:05.566436Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 1.0817 - accuracy: 0.6933\n",
      "Epoch 1: val_loss improved from inf to 0.83848, saving model to tf_TransferLearning_8Classes_best_model.hdf5\n",
      "75/75 [==============================] - 59s 787ms/step - loss: 1.0817 - accuracy: 0.6933 - val_loss: 0.8385 - val_accuracy: 0.7910 - lr: 1.0000e-05\n",
      "Epoch 2/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.6544 - accuracy: 0.8267\n",
      "Epoch 2: val_loss improved from 0.83848 to 0.79386, saving model to tf_TransferLearning_8Classes_best_model.hdf5\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.6544 - accuracy: 0.8267 - val_loss: 0.7939 - val_accuracy: 0.7915 - lr: 1.0000e-05\n",
      "Epoch 3/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.7857 - accuracy: 0.7718\n",
      "Epoch 3: val_loss did not improve from 0.79386\n",
      "75/75 [==============================] - 59s 799ms/step - loss: 0.7857 - accuracy: 0.7718 - val_loss: 0.8009 - val_accuracy: 0.7991 - lr: 1.0000e-05\n",
      "Epoch 4/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.6868 - accuracy: 0.8333\n",
      "Epoch 4: val_loss did not improve from 0.79386\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.6868 - accuracy: 0.8333 - val_loss: 0.9044 - val_accuracy: 0.7505 - lr: 1.0000e-05\n",
      "Epoch 5/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.5476 - accuracy: 0.8533\n",
      "Epoch 5: val_loss improved from 0.79386 to 0.74347, saving model to tf_TransferLearning_8Classes_best_model.hdf5\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.5476 - accuracy: 0.8533 - val_loss: 0.7435 - val_accuracy: 0.7877 - lr: 1.0000e-05\n",
      "Epoch 6/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.4544 - accuracy: 0.8733\n",
      "Epoch 6: val_loss improved from 0.74347 to 0.70217, saving model to tf_TransferLearning_8Classes_best_model.hdf5\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.4544 - accuracy: 0.8733 - val_loss: 0.7022 - val_accuracy: 0.8004 - lr: 1.0000e-05\n",
      "Epoch 7/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.4132 - accuracy: 0.8933\n",
      "Epoch 7: val_loss did not improve from 0.70217\n",
      "75/75 [==============================] - 58s 789ms/step - loss: 0.4132 - accuracy: 0.8933 - val_loss: 0.7282 - val_accuracy: 0.8164 - lr: 1.0000e-05\n",
      "Epoch 8/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.4734 - accuracy: 0.8667\n",
      "Epoch 8: val_loss improved from 0.70217 to 0.63569, saving model to tf_TransferLearning_8Classes_best_model.hdf5\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.4734 - accuracy: 0.8667 - val_loss: 0.6357 - val_accuracy: 0.8192 - lr: 1.0000e-05\n",
      "Epoch 9/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.3763 - accuracy: 0.9200\n",
      "Epoch 9: val_loss did not improve from 0.63569\n",
      "75/75 [==============================] - 59s 790ms/step - loss: 0.3763 - accuracy: 0.9200 - val_loss: 0.7170 - val_accuracy: 0.8115 - lr: 1.0000e-05\n",
      "Epoch 10/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.3266 - accuracy: 0.9000\n",
      "Epoch 10: val_loss did not improve from 0.63569\n",
      "75/75 [==============================] - 59s 798ms/step - loss: 0.3266 - accuracy: 0.9000 - val_loss: 0.6766 - val_accuracy: 0.7951 - lr: 1.0000e-05\n",
      "Epoch 11/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.3062 - accuracy: 0.9000\n",
      "Epoch 11: val_loss improved from 0.63569 to 0.60610, saving model to tf_TransferLearning_8Classes_best_model.hdf5\n",
      "75/75 [==============================] - 60s 805ms/step - loss: 0.3062 - accuracy: 0.9000 - val_loss: 0.6061 - val_accuracy: 0.8350 - lr: 9.9005e-06\n",
      "Epoch 12/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.4540 - accuracy: 0.8867\n",
      "Epoch 12: val_loss did not improve from 0.60610\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.4540 - accuracy: 0.8867 - val_loss: 0.6926 - val_accuracy: 0.8310 - lr: 9.8020e-06\n",
      "Epoch 13/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.2244 - accuracy: 0.9333\n",
      "Epoch 13: val_loss did not improve from 0.60610\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.2244 - accuracy: 0.9333 - val_loss: 0.6537 - val_accuracy: 0.8387 - lr: 9.7045e-06\n",
      "Epoch 14/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.5481 - accuracy: 0.8600\n",
      "Epoch 14: val_loss did not improve from 0.60610\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.5481 - accuracy: 0.8600 - val_loss: 0.6601 - val_accuracy: 0.8031 - lr: 9.6079e-06\n",
      "Epoch 15/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.4282 - accuracy: 0.9000\n",
      "Epoch 15: val_loss improved from 0.60610 to 0.57598, saving model to tf_TransferLearning_8Classes_best_model.hdf5\n",
      "75/75 [==============================] - 60s 805ms/step - loss: 0.4282 - accuracy: 0.9000 - val_loss: 0.5760 - val_accuracy: 0.8321 - lr: 9.5123e-06\n",
      "Epoch 16/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.3838 - accuracy: 0.9133\n",
      "Epoch 16: val_loss did not improve from 0.57598\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.3838 - accuracy: 0.9133 - val_loss: 0.6435 - val_accuracy: 0.8133 - lr: 9.4176e-06\n",
      "Epoch 17/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.2727 - accuracy: 0.9200\n",
      "Epoch 17: val_loss did not improve from 0.57598\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.2727 - accuracy: 0.9200 - val_loss: 0.6167 - val_accuracy: 0.8058 - lr: 9.3239e-06\n",
      "Epoch 18/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.4472 - accuracy: 0.8800\n",
      "Epoch 18: val_loss did not improve from 0.57598\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.4472 - accuracy: 0.8800 - val_loss: 0.5848 - val_accuracy: 0.8332 - lr: 9.2312e-06\n",
      "Epoch 19/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.3635 - accuracy: 0.9000\n",
      "Epoch 19: val_loss improved from 0.57598 to 0.52140, saving model to tf_TransferLearning_8Classes_best_model.hdf5\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.3635 - accuracy: 0.9000 - val_loss: 0.5214 - val_accuracy: 0.8519 - lr: 9.1393e-06\n",
      "Epoch 20/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.3510 - accuracy: 0.9133\n",
      "Epoch 20: val_loss did not improve from 0.52140\n",
      "75/75 [==============================] - 59s 798ms/step - loss: 0.3510 - accuracy: 0.9133 - val_loss: 0.5732 - val_accuracy: 0.8444 - lr: 9.0484e-06\n",
      "Epoch 21/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.2610 - accuracy: 0.9267\n",
      "Epoch 21: val_loss did not improve from 0.52140\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.2610 - accuracy: 0.9267 - val_loss: 0.5376 - val_accuracy: 0.8496 - lr: 8.9583e-06\n",
      "Epoch 22/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.3367 - accuracy: 0.9200\n",
      "Epoch 22: val_loss did not improve from 0.52140\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.3367 - accuracy: 0.9200 - val_loss: 0.5269 - val_accuracy: 0.8451 - lr: 8.8692e-06\n",
      "Epoch 23/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1888 - accuracy: 0.9467\n",
      "Epoch 23: val_loss did not improve from 0.52140\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.1888 - accuracy: 0.9467 - val_loss: 0.9129 - val_accuracy: 0.8133 - lr: 8.7810e-06\n",
      "Epoch 24/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.3154 - accuracy: 0.9133\n",
      "Epoch 24: val_loss improved from 0.52140 to 0.51440, saving model to tf_TransferLearning_8Classes_best_model.hdf5\n",
      "75/75 [==============================] - 59s 798ms/step - loss: 0.3154 - accuracy: 0.9133 - val_loss: 0.5144 - val_accuracy: 0.8486 - lr: 8.6936e-06\n",
      "Epoch 25/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.3516 - accuracy: 0.9000\n",
      "Epoch 25: val_loss improved from 0.51440 to 0.47694, saving model to tf_TransferLearning_8Classes_best_model.hdf5\n",
      "75/75 [==============================] - 59s 798ms/step - loss: 0.3516 - accuracy: 0.9000 - val_loss: 0.4769 - val_accuracy: 0.8617 - lr: 8.6071e-06\n",
      "Epoch 26/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.3506 - accuracy: 0.9067\n",
      "Epoch 26: val_loss improved from 0.47694 to 0.46658, saving model to tf_TransferLearning_8Classes_best_model.hdf5\n",
      "75/75 [==============================] - 59s 799ms/step - loss: 0.3506 - accuracy: 0.9067 - val_loss: 0.4666 - val_accuracy: 0.8645 - lr: 8.5214e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.3651 - accuracy: 0.9067\n",
      "Epoch 27: val_loss did not improve from 0.46658\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.3651 - accuracy: 0.9067 - val_loss: 0.4806 - val_accuracy: 0.8588 - lr: 8.4366e-06\n",
      "Epoch 28/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.2666 - accuracy: 0.9067\n",
      "Epoch 28: val_loss did not improve from 0.46658\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.2666 - accuracy: 0.9067 - val_loss: 0.7088 - val_accuracy: 0.7677 - lr: 8.3527e-06\n",
      "Epoch 29/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.2974 - accuracy: 0.8867\n",
      "Epoch 29: val_loss did not improve from 0.46658\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.2974 - accuracy: 0.8867 - val_loss: 0.6130 - val_accuracy: 0.8425 - lr: 8.2696e-06\n",
      "Epoch 30/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.3777 - accuracy: 0.8733\n",
      "Epoch 30: val_loss did not improve from 0.46658\n",
      "75/75 [==============================] - 59s 798ms/step - loss: 0.3777 - accuracy: 0.8733 - val_loss: 0.4738 - val_accuracy: 0.8597 - lr: 8.1873e-06\n",
      "Epoch 31/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.2633 - accuracy: 0.9267\n",
      "Epoch 31: val_loss did not improve from 0.46658\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.2633 - accuracy: 0.9267 - val_loss: 0.4701 - val_accuracy: 0.8682 - lr: 8.1058e-06\n",
      "Epoch 32/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.3176 - accuracy: 0.9200\n",
      "Epoch 32: val_loss did not improve from 0.46658\n",
      "75/75 [==============================] - 59s 797ms/step - loss: 0.3176 - accuracy: 0.9200 - val_loss: 0.4957 - val_accuracy: 0.8531 - lr: 8.0252e-06\n",
      "Epoch 33/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.3675 - accuracy: 0.8800\n",
      "Epoch 33: val_loss did not improve from 0.46658\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.3675 - accuracy: 0.8800 - val_loss: 0.5605 - val_accuracy: 0.8314 - lr: 7.9453e-06\n",
      "Epoch 34/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.2103 - accuracy: 0.9333\n",
      "Epoch 34: val_loss did not improve from 0.46658\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.2103 - accuracy: 0.9333 - val_loss: 0.4811 - val_accuracy: 0.8538 - lr: 7.8663e-06\n",
      "Epoch 35/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.2280 - accuracy: 0.9467\n",
      "Epoch 35: val_loss did not improve from 0.46658\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.2280 - accuracy: 0.9467 - val_loss: 0.4694 - val_accuracy: 0.8613 - lr: 7.7880e-06\n",
      "Epoch 36/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.3945 - accuracy: 0.9000\n",
      "Epoch 36: val_loss did not improve from 0.46658\n",
      "75/75 [==============================] - 59s 797ms/step - loss: 0.3945 - accuracy: 0.9000 - val_loss: 0.5065 - val_accuracy: 0.8464 - lr: 7.7105e-06\n",
      "Epoch 37/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.3124 - accuracy: 0.9133\n",
      "Epoch 37: val_loss improved from 0.46658 to 0.45898, saving model to tf_TransferLearning_8Classes_best_model.hdf5\n",
      "75/75 [==============================] - 59s 797ms/step - loss: 0.3124 - accuracy: 0.9133 - val_loss: 0.4590 - val_accuracy: 0.8644 - lr: 7.6338e-06\n",
      "Epoch 38/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.2376 - accuracy: 0.9067\n",
      "Epoch 38: val_loss improved from 0.45898 to 0.42439, saving model to tf_TransferLearning_8Classes_best_model.hdf5\n",
      "75/75 [==============================] - 59s 800ms/step - loss: 0.2376 - accuracy: 0.9067 - val_loss: 0.4244 - val_accuracy: 0.8699 - lr: 7.5578e-06\n",
      "Epoch 39/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.2785 - accuracy: 0.9133\n",
      "Epoch 39: val_loss did not improve from 0.42439\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.2785 - accuracy: 0.9133 - val_loss: 0.4888 - val_accuracy: 0.8463 - lr: 7.4826e-06\n",
      "Epoch 40/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.3055 - accuracy: 0.8933\n",
      "Epoch 40: val_loss did not improve from 0.42439\n",
      "75/75 [==============================] - 59s 797ms/step - loss: 0.3055 - accuracy: 0.8933 - val_loss: 0.4549 - val_accuracy: 0.8650 - lr: 7.4082e-06\n",
      "Epoch 41/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.2262 - accuracy: 0.9533\n",
      "Epoch 41: val_loss did not improve from 0.42439\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.2262 - accuracy: 0.9533 - val_loss: 0.4415 - val_accuracy: 0.8616 - lr: 7.3345e-06\n",
      "Epoch 42/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.3002 - accuracy: 0.9333\n",
      "Epoch 42: val_loss did not improve from 0.42439\n",
      "75/75 [==============================] - 59s 797ms/step - loss: 0.3002 - accuracy: 0.9333 - val_loss: 0.5319 - val_accuracy: 0.8441 - lr: 7.2615e-06\n",
      "Epoch 43/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.3060 - accuracy: 0.8933\n",
      "Epoch 43: val_loss did not improve from 0.42439\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.3060 - accuracy: 0.8933 - val_loss: 0.4413 - val_accuracy: 0.8652 - lr: 7.1892e-06\n",
      "Epoch 44/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1776 - accuracy: 0.9400\n",
      "Epoch 44: val_loss did not improve from 0.42439\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.1776 - accuracy: 0.9400 - val_loss: 0.4528 - val_accuracy: 0.8649 - lr: 7.1177e-06\n",
      "Epoch 45/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.2849 - accuracy: 0.9200\n",
      "Epoch 45: val_loss did not improve from 0.42439\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.2849 - accuracy: 0.9200 - val_loss: 0.4292 - val_accuracy: 0.8654 - lr: 7.0469e-06\n",
      "Epoch 46/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.2114 - accuracy: 0.9267\n",
      "Epoch 46: val_loss did not improve from 0.42439\n",
      "75/75 [==============================] - 59s 797ms/step - loss: 0.2114 - accuracy: 0.9267 - val_loss: 0.4624 - val_accuracy: 0.8573 - lr: 6.9768e-06\n",
      "Epoch 47/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.3462 - accuracy: 0.8800\n",
      "Epoch 47: val_loss did not improve from 0.42439\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.3462 - accuracy: 0.8800 - val_loss: 0.4464 - val_accuracy: 0.8667 - lr: 6.9073e-06\n",
      "Epoch 48/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.2592 - accuracy: 0.9267\n",
      "Epoch 48: val_loss did not improve from 0.42439\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.2592 - accuracy: 0.9267 - val_loss: 0.4712 - val_accuracy: 0.8645 - lr: 6.8386e-06\n",
      "Epoch 49/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1663 - accuracy: 0.9533\n",
      "Epoch 49: val_loss did not improve from 0.42439\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.1663 - accuracy: 0.9533 - val_loss: 0.4500 - val_accuracy: 0.8648 - lr: 6.7706e-06\n",
      "Epoch 50/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.2356 - accuracy: 0.9333\n",
      "Epoch 50: val_loss did not improve from 0.42439\n",
      "75/75 [==============================] - 59s 797ms/step - loss: 0.2356 - accuracy: 0.9333 - val_loss: 0.5282 - val_accuracy: 0.8485 - lr: 6.7032e-06\n",
      "Epoch 51/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.2334 - accuracy: 0.9267\n",
      "Epoch 51: val_loss did not improve from 0.42439\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.2334 - accuracy: 0.9267 - val_loss: 0.4566 - val_accuracy: 0.8579 - lr: 6.6365e-06\n",
      "Epoch 52/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1980 - accuracy: 0.9200\n",
      "Epoch 52: val_loss did not improve from 0.42439\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.1980 - accuracy: 0.9200 - val_loss: 0.5291 - val_accuracy: 0.8558 - lr: 6.5705e-06\n",
      "Epoch 53/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.2152 - accuracy: 0.9267\n",
      "Epoch 53: val_loss did not improve from 0.42439\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.2152 - accuracy: 0.9267 - val_loss: 0.5734 - val_accuracy: 0.8303 - lr: 6.5051e-06\n",
      "Epoch 54/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.2358 - accuracy: 0.9400\n",
      "Epoch 54: val_loss improved from 0.42439 to 0.38266, saving model to tf_TransferLearning_8Classes_best_model.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 59s 800ms/step - loss: 0.2358 - accuracy: 0.9400 - val_loss: 0.3827 - val_accuracy: 0.8831 - lr: 6.4404e-06\n",
      "Epoch 55/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1035 - accuracy: 0.9533\n",
      "Epoch 55: val_loss did not improve from 0.38266\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.1035 - accuracy: 0.9533 - val_loss: 0.4192 - val_accuracy: 0.8751 - lr: 6.3763e-06\n",
      "Epoch 56/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.2261 - accuracy: 0.9333\n",
      "Epoch 56: val_loss did not improve from 0.38266\n",
      "75/75 [==============================] - 59s 799ms/step - loss: 0.2261 - accuracy: 0.9333 - val_loss: 0.4364 - val_accuracy: 0.8692 - lr: 6.3128e-06\n",
      "Epoch 57/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1346 - accuracy: 0.9533\n",
      "Epoch 57: val_loss did not improve from 0.38266\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.1346 - accuracy: 0.9533 - val_loss: 0.4788 - val_accuracy: 0.8705 - lr: 6.2500e-06\n",
      "Epoch 58/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.3561 - accuracy: 0.8800\n",
      "Epoch 58: val_loss did not improve from 0.38266\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.3561 - accuracy: 0.8800 - val_loss: 0.4582 - val_accuracy: 0.8636 - lr: 6.1878e-06\n",
      "Epoch 59/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0979 - accuracy: 0.9800\n",
      "Epoch 59: val_loss did not improve from 0.38266\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.0979 - accuracy: 0.9800 - val_loss: 0.4660 - val_accuracy: 0.8756 - lr: 6.1263e-06\n",
      "Epoch 60/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1643 - accuracy: 0.9600\n",
      "Epoch 60: val_loss did not improve from 0.38266\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.1643 - accuracy: 0.9600 - val_loss: 0.4223 - val_accuracy: 0.8727 - lr: 6.0653e-06\n",
      "Epoch 61/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.2084 - accuracy: 0.9597\n",
      "Epoch 61: val_loss did not improve from 0.38266\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.2084 - accuracy: 0.9597 - val_loss: 0.4502 - val_accuracy: 0.8630 - lr: 6.0050e-06\n",
      "Epoch 62/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.2805 - accuracy: 0.9000\n",
      "Epoch 62: val_loss did not improve from 0.38266\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.2805 - accuracy: 0.9000 - val_loss: 0.4169 - val_accuracy: 0.8726 - lr: 5.9452e-06\n",
      "Epoch 63/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1140 - accuracy: 0.9667\n",
      "Epoch 63: val_loss did not improve from 0.38266\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.1140 - accuracy: 0.9667 - val_loss: 0.4355 - val_accuracy: 0.8804 - lr: 5.8861e-06\n",
      "Epoch 64/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.2327 - accuracy: 0.9133\n",
      "Epoch 64: val_loss did not improve from 0.38266\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.2327 - accuracy: 0.9133 - val_loss: 0.5059 - val_accuracy: 0.8624 - lr: 5.8275e-06\n",
      "Epoch 65/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.2813 - accuracy: 0.9200\n",
      "Epoch 65: val_loss did not improve from 0.38266\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.2813 - accuracy: 0.9200 - val_loss: 0.4151 - val_accuracy: 0.8720 - lr: 5.7695e-06\n",
      "Epoch 66/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.2163 - accuracy: 0.9267\n",
      "Epoch 66: val_loss did not improve from 0.38266\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.2163 - accuracy: 0.9267 - val_loss: 0.4393 - val_accuracy: 0.8737 - lr: 5.7121e-06\n",
      "Epoch 67/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.3037 - accuracy: 0.9067\n",
      "Epoch 67: val_loss improved from 0.38266 to 0.36599, saving model to tf_TransferLearning_8Classes_best_model.hdf5\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.3037 - accuracy: 0.9067 - val_loss: 0.3660 - val_accuracy: 0.8836 - lr: 5.6553e-06\n",
      "Epoch 68/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.2177 - accuracy: 0.9333\n",
      "Epoch 68: val_loss did not improve from 0.36599\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.2177 - accuracy: 0.9333 - val_loss: 0.4064 - val_accuracy: 0.8758 - lr: 5.5990e-06\n",
      "Epoch 69/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1368 - accuracy: 0.9733\n",
      "Epoch 69: val_loss did not improve from 0.36599\n",
      "75/75 [==============================] - 59s 790ms/step - loss: 0.1368 - accuracy: 0.9733 - val_loss: 0.5605 - val_accuracy: 0.8524 - lr: 5.5433e-06\n",
      "Epoch 70/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.2643 - accuracy: 0.9133\n",
      "Epoch 70: val_loss did not improve from 0.36599\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.2643 - accuracy: 0.9133 - val_loss: 0.4056 - val_accuracy: 0.8806 - lr: 5.4881e-06\n",
      "Epoch 71/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1655 - accuracy: 0.9600\n",
      "Epoch 71: val_loss did not improve from 0.36599\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.1655 - accuracy: 0.9600 - val_loss: 0.3865 - val_accuracy: 0.8811 - lr: 5.4335e-06\n",
      "Epoch 72/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1434 - accuracy: 0.9533\n",
      "Epoch 72: val_loss did not improve from 0.36599\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.1434 - accuracy: 0.9533 - val_loss: 0.3897 - val_accuracy: 0.8784 - lr: 5.3794e-06\n",
      "Epoch 73/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.2654 - accuracy: 0.9267\n",
      "Epoch 73: val_loss did not improve from 0.36599\n",
      "75/75 [==============================] - 59s 791ms/step - loss: 0.2654 - accuracy: 0.9267 - val_loss: 0.4543 - val_accuracy: 0.8713 - lr: 5.3259e-06\n",
      "Epoch 74/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1808 - accuracy: 0.9333\n",
      "Epoch 74: val_loss did not improve from 0.36599\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.1808 - accuracy: 0.9333 - val_loss: 0.4581 - val_accuracy: 0.8665 - lr: 5.2729e-06\n",
      "Epoch 75/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1827 - accuracy: 0.9333\n",
      "Epoch 75: val_loss did not improve from 0.36599\n",
      "75/75 [==============================] - 59s 791ms/step - loss: 0.1827 - accuracy: 0.9333 - val_loss: 0.3968 - val_accuracy: 0.8794 - lr: 5.2205e-06\n",
      "Epoch 76/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1251 - accuracy: 0.9667\n",
      "Epoch 76: val_loss did not improve from 0.36599\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.1251 - accuracy: 0.9667 - val_loss: 0.4343 - val_accuracy: 0.8685 - lr: 5.1685e-06\n",
      "Epoch 77/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1581 - accuracy: 0.9400\n",
      "Epoch 77: val_loss did not improve from 0.36599\n",
      "75/75 [==============================] - 59s 791ms/step - loss: 0.1581 - accuracy: 0.9400 - val_loss: 0.4271 - val_accuracy: 0.8710 - lr: 5.1171e-06\n",
      "Epoch 78/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.2454 - accuracy: 0.9467\n",
      "Epoch 78: val_loss did not improve from 0.36599\n",
      "75/75 [==============================] - 59s 791ms/step - loss: 0.2454 - accuracy: 0.9467 - val_loss: 0.3831 - val_accuracy: 0.8833 - lr: 5.0662e-06\n",
      "Epoch 79/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1836 - accuracy: 0.9267\n",
      "Epoch 79: val_loss did not improve from 0.36599\n",
      "75/75 [==============================] - 59s 791ms/step - loss: 0.1836 - accuracy: 0.9267 - val_loss: 0.4479 - val_accuracy: 0.8684 - lr: 5.0158e-06\n",
      "Epoch 80/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.2327 - accuracy: 0.9267\n",
      "Epoch 80: val_loss did not improve from 0.36599\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.2327 - accuracy: 0.9267 - val_loss: 0.4022 - val_accuracy: 0.8796 - lr: 4.9659e-06\n",
      "Epoch 81/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1436 - accuracy: 0.9667\n",
      "Epoch 81: val_loss did not improve from 0.36599\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.1436 - accuracy: 0.9667 - val_loss: 0.3967 - val_accuracy: 0.8813 - lr: 4.9164e-06\n",
      "Epoch 82/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - ETA: 0s - loss: 0.1138 - accuracy: 0.9667\n",
      "Epoch 82: val_loss did not improve from 0.36599\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.1138 - accuracy: 0.9667 - val_loss: 0.4417 - val_accuracy: 0.8762 - lr: 4.8675e-06\n",
      "Epoch 83/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.2005 - accuracy: 0.9267\n",
      "Epoch 83: val_loss did not improve from 0.36599\n",
      "75/75 [==============================] - 58s 789ms/step - loss: 0.2005 - accuracy: 0.9267 - val_loss: 0.4171 - val_accuracy: 0.8783 - lr: 4.8191e-06\n",
      "Epoch 84/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1841 - accuracy: 0.9467\n",
      "Epoch 84: val_loss did not improve from 0.36599\n",
      "75/75 [==============================] - 59s 791ms/step - loss: 0.1841 - accuracy: 0.9467 - val_loss: 0.3984 - val_accuracy: 0.8796 - lr: 4.7711e-06\n",
      "Epoch 85/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1577 - accuracy: 0.9400\n",
      "Epoch 85: val_loss did not improve from 0.36599\n",
      "75/75 [==============================] - 59s 790ms/step - loss: 0.1577 - accuracy: 0.9400 - val_loss: 0.3898 - val_accuracy: 0.8840 - lr: 4.7237e-06\n",
      "Epoch 86/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1383 - accuracy: 0.9667\n",
      "Epoch 86: val_loss did not improve from 0.36599\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.1383 - accuracy: 0.9667 - val_loss: 0.3778 - val_accuracy: 0.8862 - lr: 4.6767e-06\n",
      "Epoch 87/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1430 - accuracy: 0.9600\n",
      "Epoch 87: val_loss did not improve from 0.36599\n",
      "75/75 [==============================] - 59s 791ms/step - loss: 0.1430 - accuracy: 0.9600 - val_loss: 0.4056 - val_accuracy: 0.8854 - lr: 4.6301e-06\n",
      "Epoch 88/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1664 - accuracy: 0.9467\n",
      "Epoch 88: val_loss did not improve from 0.36599\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.1664 - accuracy: 0.9467 - val_loss: 0.4926 - val_accuracy: 0.8686 - lr: 4.5841e-06\n",
      "Epoch 89/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.2406 - accuracy: 0.9000\n",
      "Epoch 89: val_loss did not improve from 0.36599\n",
      "75/75 [==============================] - 59s 791ms/step - loss: 0.2406 - accuracy: 0.9000 - val_loss: 0.4095 - val_accuracy: 0.8756 - lr: 4.5384e-06\n",
      "Epoch 90/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.2207 - accuracy: 0.9400\n",
      "Epoch 90: val_loss did not improve from 0.36599\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.2207 - accuracy: 0.9400 - val_loss: 0.4036 - val_accuracy: 0.8780 - lr: 4.4933e-06\n",
      "Epoch 91/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1146 - accuracy: 0.9733\n",
      "Epoch 91: val_loss did not improve from 0.36599\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.1146 - accuracy: 0.9733 - val_loss: 0.4439 - val_accuracy: 0.8633 - lr: 4.4486e-06\n",
      "Epoch 92/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.2388 - accuracy: 0.9467\n",
      "Epoch 92: val_loss did not improve from 0.36599\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.2388 - accuracy: 0.9467 - val_loss: 0.4006 - val_accuracy: 0.8792 - lr: 4.4043e-06\n",
      "Epoch 93/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1357 - accuracy: 0.9467\n",
      "Epoch 93: val_loss did not improve from 0.36599\n",
      "75/75 [==============================] - 59s 791ms/step - loss: 0.1357 - accuracy: 0.9467 - val_loss: 0.4087 - val_accuracy: 0.8787 - lr: 4.3605e-06\n",
      "Epoch 94/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1488 - accuracy: 0.9533\n",
      "Epoch 94: val_loss did not improve from 0.36599\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.1488 - accuracy: 0.9533 - val_loss: 0.3863 - val_accuracy: 0.8821 - lr: 4.3171e-06\n",
      "Epoch 95/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1245 - accuracy: 0.9600\n",
      "Epoch 95: val_loss did not improve from 0.36599\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.1245 - accuracy: 0.9600 - val_loss: 0.4120 - val_accuracy: 0.8801 - lr: 4.2742e-06\n",
      "Epoch 96/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1494 - accuracy: 0.9667\n",
      "Epoch 96: val_loss did not improve from 0.36599\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.1494 - accuracy: 0.9667 - val_loss: 0.3732 - val_accuracy: 0.8883 - lr: 4.2316e-06\n",
      "Epoch 97/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1669 - accuracy: 0.9333\n",
      "Epoch 97: val_loss improved from 0.36599 to 0.36525, saving model to tf_TransferLearning_8Classes_best_model.hdf5\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.1669 - accuracy: 0.9333 - val_loss: 0.3653 - val_accuracy: 0.8906 - lr: 4.1895e-06\n",
      "Epoch 98/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1472 - accuracy: 0.9600\n",
      "Epoch 98: val_loss did not improve from 0.36525\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.1472 - accuracy: 0.9600 - val_loss: 0.3897 - val_accuracy: 0.8877 - lr: 4.1478e-06\n",
      "Epoch 99/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1990 - accuracy: 0.9600\n",
      "Epoch 99: val_loss improved from 0.36525 to 0.35739, saving model to tf_TransferLearning_8Classes_best_model.hdf5\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.1990 - accuracy: 0.9600 - val_loss: 0.3574 - val_accuracy: 0.8923 - lr: 4.1066e-06\n",
      "Epoch 100/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1572 - accuracy: 0.9600\n",
      "Epoch 100: val_loss did not improve from 0.35739\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.1572 - accuracy: 0.9600 - val_loss: 0.3779 - val_accuracy: 0.8853 - lr: 4.0657e-06\n",
      "Epoch 101/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0925 - accuracy: 0.9600\n",
      "Epoch 101: val_loss did not improve from 0.35739\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.0925 - accuracy: 0.9600 - val_loss: 0.4249 - val_accuracy: 0.8842 - lr: 4.0252e-06\n",
      "Epoch 102/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1671 - accuracy: 0.9600\n",
      "Epoch 102: val_loss did not improve from 0.35739\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.1671 - accuracy: 0.9600 - val_loss: 0.4199 - val_accuracy: 0.8790 - lr: 4.0252e-06\n",
      "Epoch 103/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1698 - accuracy: 0.9467\n",
      "Epoch 103: val_loss did not improve from 0.35739\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.1698 - accuracy: 0.9467 - val_loss: 0.4307 - val_accuracy: 0.8736 - lr: 4.0252e-06\n",
      "Epoch 104/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0608 - accuracy: 0.9800\n",
      "Epoch 104: val_loss did not improve from 0.35739\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.0608 - accuracy: 0.9800 - val_loss: 0.4288 - val_accuracy: 0.8821 - lr: 4.0252e-06\n",
      "Epoch 105/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0704 - accuracy: 0.9867\n",
      "Epoch 105: val_loss did not improve from 0.35739\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.0704 - accuracy: 0.9867 - val_loss: 0.4437 - val_accuracy: 0.8814 - lr: 4.0252e-06\n",
      "Epoch 106/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1621 - accuracy: 0.9400\n",
      "Epoch 106: val_loss did not improve from 0.35739\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.1621 - accuracy: 0.9400 - val_loss: 0.6077 - val_accuracy: 0.8054 - lr: 4.0252e-06\n",
      "Epoch 107/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.2353 - accuracy: 0.9333\n",
      "Epoch 107: val_loss did not improve from 0.35739\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.2353 - accuracy: 0.9333 - val_loss: 0.3895 - val_accuracy: 0.8842 - lr: 4.0252e-06\n",
      "Epoch 108/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1262 - accuracy: 0.9333\n",
      "Epoch 108: val_loss did not improve from 0.35739\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.1262 - accuracy: 0.9333 - val_loss: 0.3928 - val_accuracy: 0.8863 - lr: 4.0252e-06\n",
      "Epoch 109/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1280 - accuracy: 0.9733\n",
      "Epoch 109: val_loss did not improve from 0.35739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 59s 793ms/step - loss: 0.1280 - accuracy: 0.9733 - val_loss: 0.4022 - val_accuracy: 0.8895 - lr: 4.0252e-06\n",
      "Epoch 110/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0937 - accuracy: 0.9800\n",
      "Epoch 110: val_loss did not improve from 0.35739\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.0937 - accuracy: 0.9800 - val_loss: 0.3741 - val_accuracy: 0.8945 - lr: 4.0252e-06\n",
      "Epoch 111/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.2737 - accuracy: 0.9267\n",
      "Epoch 111: val_loss did not improve from 0.35739\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.2737 - accuracy: 0.9267 - val_loss: 0.4090 - val_accuracy: 0.8835 - lr: 4.0252e-06\n",
      "Epoch 112/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1869 - accuracy: 0.9400\n",
      "Epoch 112: val_loss did not improve from 0.35739\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.1869 - accuracy: 0.9400 - val_loss: 0.4220 - val_accuracy: 0.8766 - lr: 4.0252e-06\n",
      "Epoch 113/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1341 - accuracy: 0.9667\n",
      "Epoch 113: val_loss did not improve from 0.35739\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.1341 - accuracy: 0.9667 - val_loss: 0.3957 - val_accuracy: 0.8854 - lr: 4.0252e-06\n",
      "Epoch 114/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0925 - accuracy: 0.9667\n",
      "Epoch 114: val_loss did not improve from 0.35739\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.0925 - accuracy: 0.9667 - val_loss: 0.4135 - val_accuracy: 0.8825 - lr: 4.0252e-06\n",
      "Epoch 115/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0755 - accuracy: 0.9600\n",
      "Epoch 115: val_loss did not improve from 0.35739\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.0755 - accuracy: 0.9600 - val_loss: 0.4300 - val_accuracy: 0.8814 - lr: 4.0252e-06\n",
      "Epoch 116/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1501 - accuracy: 0.9467\n",
      "Epoch 116: val_loss did not improve from 0.35739\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.1501 - accuracy: 0.9467 - val_loss: 0.4030 - val_accuracy: 0.8808 - lr: 4.0252e-06\n",
      "Epoch 117/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.2449 - accuracy: 0.9133\n",
      "Epoch 117: val_loss did not improve from 0.35739\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.2449 - accuracy: 0.9133 - val_loss: 0.3651 - val_accuracy: 0.8868 - lr: 4.0252e-06\n",
      "Epoch 118/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1274 - accuracy: 0.9533\n",
      "Epoch 118: val_loss improved from 0.35739 to 0.35367, saving model to tf_TransferLearning_8Classes_best_model.hdf5\n",
      "75/75 [==============================] - 59s 799ms/step - loss: 0.1274 - accuracy: 0.9533 - val_loss: 0.3537 - val_accuracy: 0.8896 - lr: 4.0252e-06\n",
      "Epoch 119/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1490 - accuracy: 0.9200\n",
      "Epoch 119: val_loss did not improve from 0.35367\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.1490 - accuracy: 0.9200 - val_loss: 0.3641 - val_accuracy: 0.8885 - lr: 4.0252e-06\n",
      "Epoch 120/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.2478 - accuracy: 0.9333\n",
      "Epoch 120: val_loss did not improve from 0.35367\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.2478 - accuracy: 0.9333 - val_loss: 0.3914 - val_accuracy: 0.8857 - lr: 4.0252e-06\n",
      "Epoch 121/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0781 - accuracy: 0.9733\n",
      "Epoch 121: val_loss improved from 0.35367 to 0.34986, saving model to tf_TransferLearning_8Classes_best_model.hdf5\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.0781 - accuracy: 0.9733 - val_loss: 0.3499 - val_accuracy: 0.8933 - lr: 4.0252e-06\n",
      "Epoch 122/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1619 - accuracy: 0.9600\n",
      "Epoch 122: val_loss did not improve from 0.34986\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.1619 - accuracy: 0.9600 - val_loss: 0.3834 - val_accuracy: 0.8831 - lr: 4.0252e-06\n",
      "Epoch 123/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1441 - accuracy: 0.9467\n",
      "Epoch 123: val_loss did not improve from 0.34986\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.1441 - accuracy: 0.9467 - val_loss: 0.4026 - val_accuracy: 0.8857 - lr: 4.0252e-06\n",
      "Epoch 124/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1057 - accuracy: 0.9600\n",
      "Epoch 124: val_loss did not improve from 0.34986\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.1057 - accuracy: 0.9600 - val_loss: 0.3668 - val_accuracy: 0.8919 - lr: 4.0252e-06\n",
      "Epoch 125/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1813 - accuracy: 0.9400\n",
      "Epoch 125: val_loss did not improve from 0.34986\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.1813 - accuracy: 0.9400 - val_loss: 0.3534 - val_accuracy: 0.8954 - lr: 4.0252e-06\n",
      "Epoch 126/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.2548 - accuracy: 0.9467\n",
      "Epoch 126: val_loss did not improve from 0.34986\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.2548 - accuracy: 0.9467 - val_loss: 0.3608 - val_accuracy: 0.8902 - lr: 4.0252e-06\n",
      "Epoch 127/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1031 - accuracy: 0.9800\n",
      "Epoch 127: val_loss did not improve from 0.34986\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.1031 - accuracy: 0.9800 - val_loss: 0.3766 - val_accuracy: 0.8880 - lr: 4.0252e-06\n",
      "Epoch 128/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0966 - accuracy: 0.9600\n",
      "Epoch 128: val_loss improved from 0.34986 to 0.34091, saving model to tf_TransferLearning_8Classes_best_model.hdf5\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.0966 - accuracy: 0.9600 - val_loss: 0.3409 - val_accuracy: 0.8962 - lr: 4.0252e-06\n",
      "Epoch 129/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1594 - accuracy: 0.9200\n",
      "Epoch 129: val_loss did not improve from 0.34091\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.1594 - accuracy: 0.9200 - val_loss: 0.3977 - val_accuracy: 0.8816 - lr: 4.0252e-06\n",
      "Epoch 130/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.2863 - accuracy: 0.9000\n",
      "Epoch 130: val_loss did not improve from 0.34091\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.2863 - accuracy: 0.9000 - val_loss: 0.3576 - val_accuracy: 0.8912 - lr: 4.0252e-06\n",
      "Epoch 131/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.2262 - accuracy: 0.9267\n",
      "Epoch 131: val_loss did not improve from 0.34091\n",
      "75/75 [==============================] - 59s 791ms/step - loss: 0.2262 - accuracy: 0.9267 - val_loss: 0.3418 - val_accuracy: 0.8965 - lr: 4.0252e-06\n",
      "Epoch 132/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1519 - accuracy: 0.9467\n",
      "Epoch 132: val_loss improved from 0.34091 to 0.33575, saving model to tf_TransferLearning_8Classes_best_model.hdf5\n",
      "75/75 [==============================] - 59s 797ms/step - loss: 0.1519 - accuracy: 0.9467 - val_loss: 0.3358 - val_accuracy: 0.8983 - lr: 4.0252e-06\n",
      "Epoch 133/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1507 - accuracy: 0.9467\n",
      "Epoch 133: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 791ms/step - loss: 0.1507 - accuracy: 0.9467 - val_loss: 0.3786 - val_accuracy: 0.8918 - lr: 4.0252e-06\n",
      "Epoch 134/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1223 - accuracy: 0.9667\n",
      "Epoch 134: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.1223 - accuracy: 0.9667 - val_loss: 0.3410 - val_accuracy: 0.8976 - lr: 4.0252e-06\n",
      "Epoch 135/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1182 - accuracy: 0.9667\n",
      "Epoch 135: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 791ms/step - loss: 0.1182 - accuracy: 0.9667 - val_loss: 0.4121 - val_accuracy: 0.8849 - lr: 4.0252e-06\n",
      "Epoch 136/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1151 - accuracy: 0.9600\n",
      "Epoch 136: val_loss did not improve from 0.33575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 59s 793ms/step - loss: 0.1151 - accuracy: 0.9600 - val_loss: 0.4919 - val_accuracy: 0.8637 - lr: 4.0252e-06\n",
      "Epoch 137/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0949 - accuracy: 0.9733\n",
      "Epoch 137: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 791ms/step - loss: 0.0949 - accuracy: 0.9733 - val_loss: 0.3798 - val_accuracy: 0.8904 - lr: 4.0252e-06\n",
      "Epoch 138/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1144 - accuracy: 0.9600\n",
      "Epoch 138: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.1144 - accuracy: 0.9600 - val_loss: 0.5266 - val_accuracy: 0.8801 - lr: 4.0252e-06\n",
      "Epoch 139/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0815 - accuracy: 0.9733\n",
      "Epoch 139: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 791ms/step - loss: 0.0815 - accuracy: 0.9733 - val_loss: 0.4860 - val_accuracy: 0.8792 - lr: 4.0252e-06\n",
      "Epoch 140/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1309 - accuracy: 0.9600\n",
      "Epoch 140: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.1309 - accuracy: 0.9600 - val_loss: 0.5626 - val_accuracy: 0.8526 - lr: 4.0252e-06\n",
      "Epoch 141/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1387 - accuracy: 0.9533\n",
      "Epoch 141: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 791ms/step - loss: 0.1387 - accuracy: 0.9533 - val_loss: 0.5142 - val_accuracy: 0.8708 - lr: 4.0252e-06\n",
      "Epoch 142/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1962 - accuracy: 0.9333\n",
      "Epoch 142: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.1962 - accuracy: 0.9333 - val_loss: 0.3745 - val_accuracy: 0.8883 - lr: 4.0252e-06\n",
      "Epoch 143/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1715 - accuracy: 0.9400\n",
      "Epoch 143: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 791ms/step - loss: 0.1715 - accuracy: 0.9400 - val_loss: 0.3726 - val_accuracy: 0.8870 - lr: 4.0252e-06\n",
      "Epoch 144/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.2131 - accuracy: 0.9333\n",
      "Epoch 144: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.2131 - accuracy: 0.9333 - val_loss: 0.4511 - val_accuracy: 0.8775 - lr: 4.0252e-06\n",
      "Epoch 145/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1659 - accuracy: 0.9333\n",
      "Epoch 145: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 790ms/step - loss: 0.1659 - accuracy: 0.9333 - val_loss: 0.3763 - val_accuracy: 0.8924 - lr: 4.0252e-06\n",
      "Epoch 146/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1480 - accuracy: 0.9667\n",
      "Epoch 146: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.1480 - accuracy: 0.9667 - val_loss: 0.3629 - val_accuracy: 0.8899 - lr: 4.0252e-06\n",
      "Epoch 147/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1274 - accuracy: 0.9600\n",
      "Epoch 147: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.1274 - accuracy: 0.9600 - val_loss: 0.3997 - val_accuracy: 0.8815 - lr: 4.0252e-06\n",
      "Epoch 148/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.2563 - accuracy: 0.9333\n",
      "Epoch 148: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.2563 - accuracy: 0.9333 - val_loss: 0.3915 - val_accuracy: 0.8868 - lr: 4.0252e-06\n",
      "Epoch 149/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1926 - accuracy: 0.9533\n",
      "Epoch 149: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.1926 - accuracy: 0.9533 - val_loss: 0.4092 - val_accuracy: 0.8875 - lr: 4.0252e-06\n",
      "Epoch 150/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1282 - accuracy: 0.9667\n",
      "Epoch 150: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.1282 - accuracy: 0.9667 - val_loss: 0.4348 - val_accuracy: 0.8783 - lr: 4.0252e-06\n",
      "Epoch 151/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1170 - accuracy: 0.9667\n",
      "Epoch 151: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 791ms/step - loss: 0.1170 - accuracy: 0.9667 - val_loss: 0.4326 - val_accuracy: 0.8745 - lr: 4.0252e-06\n",
      "Epoch 152/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0960 - accuracy: 0.9667\n",
      "Epoch 152: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.0960 - accuracy: 0.9667 - val_loss: 0.4118 - val_accuracy: 0.8879 - lr: 4.0252e-06\n",
      "Epoch 153/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.2596 - accuracy: 0.9329\n",
      "Epoch 153: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 791ms/step - loss: 0.2596 - accuracy: 0.9329 - val_loss: 0.4633 - val_accuracy: 0.8581 - lr: 4.0252e-06\n",
      "Epoch 154/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0990 - accuracy: 0.9800\n",
      "Epoch 154: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.0990 - accuracy: 0.9800 - val_loss: 0.3774 - val_accuracy: 0.8869 - lr: 4.0252e-06\n",
      "Epoch 155/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0767 - accuracy: 0.9867\n",
      "Epoch 155: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 791ms/step - loss: 0.0767 - accuracy: 0.9867 - val_loss: 0.3785 - val_accuracy: 0.8885 - lr: 4.0252e-06\n",
      "Epoch 156/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0726 - accuracy: 0.9667\n",
      "Epoch 156: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.0726 - accuracy: 0.9667 - val_loss: 0.4326 - val_accuracy: 0.8811 - lr: 4.0252e-06\n",
      "Epoch 157/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0513 - accuracy: 0.9800\n",
      "Epoch 157: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 791ms/step - loss: 0.0513 - accuracy: 0.9800 - val_loss: 0.4400 - val_accuracy: 0.8806 - lr: 4.0252e-06\n",
      "Epoch 158/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.2670 - accuracy: 0.9133\n",
      "Epoch 158: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.2670 - accuracy: 0.9133 - val_loss: 0.3938 - val_accuracy: 0.8834 - lr: 4.0252e-06\n",
      "Epoch 159/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.2013 - accuracy: 0.9133\n",
      "Epoch 159: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.2013 - accuracy: 0.9133 - val_loss: 0.4114 - val_accuracy: 0.8847 - lr: 4.0252e-06\n",
      "Epoch 160/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1238 - accuracy: 0.9400\n",
      "Epoch 160: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.1238 - accuracy: 0.9400 - val_loss: 0.4102 - val_accuracy: 0.8861 - lr: 4.0252e-06\n",
      "Epoch 161/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1007 - accuracy: 0.9733\n",
      "Epoch 161: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.1007 - accuracy: 0.9733 - val_loss: 0.3634 - val_accuracy: 0.8940 - lr: 4.0252e-06\n",
      "Epoch 162/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1409 - accuracy: 0.9467\n",
      "Epoch 162: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.1409 - accuracy: 0.9467 - val_loss: 0.3615 - val_accuracy: 0.8952 - lr: 4.0252e-06\n",
      "Epoch 163/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1629 - accuracy: 0.9467\n",
      "Epoch 163: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.1629 - accuracy: 0.9467 - val_loss: 0.3719 - val_accuracy: 0.8917 - lr: 4.0252e-06\n",
      "Epoch 164/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - ETA: 0s - loss: 0.0941 - accuracy: 0.9867\n",
      "Epoch 164: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.0941 - accuracy: 0.9867 - val_loss: 0.4534 - val_accuracy: 0.8750 - lr: 4.0252e-06\n",
      "Epoch 165/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0966 - accuracy: 0.9667\n",
      "Epoch 165: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.0966 - accuracy: 0.9667 - val_loss: 0.3889 - val_accuracy: 0.8884 - lr: 4.0252e-06\n",
      "Epoch 166/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1026 - accuracy: 0.9600\n",
      "Epoch 166: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.1026 - accuracy: 0.9600 - val_loss: 0.4615 - val_accuracy: 0.8763 - lr: 4.0252e-06\n",
      "Epoch 167/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1783 - accuracy: 0.9600\n",
      "Epoch 167: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 791ms/step - loss: 0.1783 - accuracy: 0.9600 - val_loss: 0.4055 - val_accuracy: 0.8824 - lr: 4.0252e-06\n",
      "Epoch 168/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1723 - accuracy: 0.9400\n",
      "Epoch 168: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.1723 - accuracy: 0.9400 - val_loss: 0.4092 - val_accuracy: 0.8789 - lr: 4.0252e-06\n",
      "Epoch 169/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1485 - accuracy: 0.9333\n",
      "Epoch 169: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 791ms/step - loss: 0.1485 - accuracy: 0.9333 - val_loss: 0.3451 - val_accuracy: 0.8940 - lr: 4.0252e-06\n",
      "Epoch 170/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1181 - accuracy: 0.9733\n",
      "Epoch 170: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.1181 - accuracy: 0.9733 - val_loss: 0.4285 - val_accuracy: 0.8789 - lr: 4.0252e-06\n",
      "Epoch 171/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1456 - accuracy: 0.9667\n",
      "Epoch 171: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.1456 - accuracy: 0.9667 - val_loss: 0.3497 - val_accuracy: 0.8934 - lr: 4.0252e-06\n",
      "Epoch 172/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1556 - accuracy: 0.9467\n",
      "Epoch 172: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.1556 - accuracy: 0.9467 - val_loss: 0.3854 - val_accuracy: 0.8830 - lr: 4.0252e-06\n",
      "Epoch 173/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0639 - accuracy: 0.9800\n",
      "Epoch 173: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.0639 - accuracy: 0.9800 - val_loss: 0.3930 - val_accuracy: 0.8890 - lr: 4.0252e-06\n",
      "Epoch 174/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1679 - accuracy: 0.9733\n",
      "Epoch 174: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.1679 - accuracy: 0.9733 - val_loss: 0.3618 - val_accuracy: 0.8909 - lr: 4.0252e-06\n",
      "Epoch 175/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1557 - accuracy: 0.9533\n",
      "Epoch 175: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 791ms/step - loss: 0.1557 - accuracy: 0.9533 - val_loss: 0.4125 - val_accuracy: 0.8774 - lr: 4.0252e-06\n",
      "Epoch 176/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0954 - accuracy: 0.9600\n",
      "Epoch 176: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.0954 - accuracy: 0.9600 - val_loss: 0.3872 - val_accuracy: 0.8878 - lr: 4.0252e-06\n",
      "Epoch 177/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0869 - accuracy: 0.9667\n",
      "Epoch 177: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.0869 - accuracy: 0.9667 - val_loss: 0.4105 - val_accuracy: 0.8904 - lr: 4.0252e-06\n",
      "Epoch 178/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0947 - accuracy: 0.9667\n",
      "Epoch 178: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.0947 - accuracy: 0.9667 - val_loss: 0.3714 - val_accuracy: 0.8940 - lr: 4.0252e-06\n",
      "Epoch 179/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0996 - accuracy: 0.9733\n",
      "Epoch 179: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.0996 - accuracy: 0.9733 - val_loss: 0.4869 - val_accuracy: 0.8674 - lr: 4.0252e-06\n",
      "Epoch 180/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0692 - accuracy: 0.9867\n",
      "Epoch 180: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.0692 - accuracy: 0.9867 - val_loss: 0.4284 - val_accuracy: 0.8879 - lr: 4.0252e-06\n",
      "Epoch 181/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1281 - accuracy: 0.9333\n",
      "Epoch 181: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.1281 - accuracy: 0.9333 - val_loss: 0.4594 - val_accuracy: 0.8820 - lr: 4.0252e-06\n",
      "Epoch 182/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0722 - accuracy: 0.9733\n",
      "Epoch 182: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.0722 - accuracy: 0.9733 - val_loss: 0.5077 - val_accuracy: 0.8840 - lr: 4.0252e-06\n",
      "Epoch 183/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1898 - accuracy: 0.9467\n",
      "Epoch 183: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.1898 - accuracy: 0.9467 - val_loss: 0.4691 - val_accuracy: 0.8720 - lr: 4.0252e-06\n",
      "Epoch 184/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1189 - accuracy: 0.9667\n",
      "Epoch 184: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.1189 - accuracy: 0.9667 - val_loss: 0.4433 - val_accuracy: 0.8787 - lr: 4.0252e-06\n",
      "Epoch 185/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0877 - accuracy: 0.9733\n",
      "Epoch 185: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.0877 - accuracy: 0.9733 - val_loss: 0.4137 - val_accuracy: 0.8861 - lr: 4.0252e-06\n",
      "Epoch 186/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0850 - accuracy: 0.9800\n",
      "Epoch 186: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.0850 - accuracy: 0.9800 - val_loss: 0.4061 - val_accuracy: 0.8885 - lr: 4.0252e-06\n",
      "Epoch 187/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1138 - accuracy: 0.9667\n",
      "Epoch 187: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 791ms/step - loss: 0.1138 - accuracy: 0.9667 - val_loss: 0.4192 - val_accuracy: 0.8789 - lr: 4.0252e-06\n",
      "Epoch 188/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1017 - accuracy: 0.9733\n",
      "Epoch 188: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.1017 - accuracy: 0.9733 - val_loss: 0.3609 - val_accuracy: 0.8929 - lr: 4.0252e-06\n",
      "Epoch 189/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1064 - accuracy: 0.9400\n",
      "Epoch 189: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.1064 - accuracy: 0.9400 - val_loss: 0.3826 - val_accuracy: 0.8925 - lr: 4.0252e-06\n",
      "Epoch 190/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0854 - accuracy: 0.9600\n",
      "Epoch 190: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.0854 - accuracy: 0.9600 - val_loss: 0.3840 - val_accuracy: 0.8952 - lr: 4.0252e-06\n",
      "Epoch 191/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0469 - accuracy: 0.9733\n",
      "Epoch 191: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.0469 - accuracy: 0.9733 - val_loss: 0.4600 - val_accuracy: 0.8849 - lr: 4.0252e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0924 - accuracy: 0.9667\n",
      "Epoch 192: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.0924 - accuracy: 0.9667 - val_loss: 0.4217 - val_accuracy: 0.8891 - lr: 4.0252e-06\n",
      "Epoch 193/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0944 - accuracy: 0.9867\n",
      "Epoch 193: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.0944 - accuracy: 0.9867 - val_loss: 0.4348 - val_accuracy: 0.8838 - lr: 4.0252e-06\n",
      "Epoch 194/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0740 - accuracy: 0.9733\n",
      "Epoch 194: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.0740 - accuracy: 0.9733 - val_loss: 0.3705 - val_accuracy: 0.8986 - lr: 4.0252e-06\n",
      "Epoch 195/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1448 - accuracy: 0.9600\n",
      "Epoch 195: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.1448 - accuracy: 0.9600 - val_loss: 0.3513 - val_accuracy: 0.8981 - lr: 4.0252e-06\n",
      "Epoch 196/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0899 - accuracy: 0.9867\n",
      "Epoch 196: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.0899 - accuracy: 0.9867 - val_loss: 0.4048 - val_accuracy: 0.8929 - lr: 4.0252e-06\n",
      "Epoch 197/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1238 - accuracy: 0.9400\n",
      "Epoch 197: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.1238 - accuracy: 0.9400 - val_loss: 0.4124 - val_accuracy: 0.8945 - lr: 4.0252e-06\n",
      "Epoch 198/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.2135 - accuracy: 0.9400\n",
      "Epoch 198: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.2135 - accuracy: 0.9400 - val_loss: 0.3866 - val_accuracy: 0.8904 - lr: 4.0252e-06\n",
      "Epoch 199/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1303 - accuracy: 0.9600\n",
      "Epoch 199: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.1303 - accuracy: 0.9600 - val_loss: 0.4029 - val_accuracy: 0.8858 - lr: 4.0252e-06\n",
      "Epoch 200/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1161 - accuracy: 0.9667\n",
      "Epoch 200: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.1161 - accuracy: 0.9667 - val_loss: 0.3969 - val_accuracy: 0.8879 - lr: 4.0252e-06\n",
      "Epoch 201/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1220 - accuracy: 0.9667\n",
      "Epoch 201: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.1220 - accuracy: 0.9667 - val_loss: 0.4665 - val_accuracy: 0.8706 - lr: 4.0252e-06\n",
      "Epoch 202/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0415 - accuracy: 0.9867\n",
      "Epoch 202: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.0415 - accuracy: 0.9867 - val_loss: 0.4219 - val_accuracy: 0.8867 - lr: 4.0252e-06\n",
      "Epoch 203/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1651 - accuracy: 0.9333\n",
      "Epoch 203: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.1651 - accuracy: 0.9333 - val_loss: 0.4767 - val_accuracy: 0.8727 - lr: 4.0252e-06\n",
      "Epoch 204/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1817 - accuracy: 0.9400\n",
      "Epoch 204: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.1817 - accuracy: 0.9400 - val_loss: 0.4720 - val_accuracy: 0.8772 - lr: 4.0252e-06\n",
      "Epoch 205/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1371 - accuracy: 0.9467\n",
      "Epoch 205: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 791ms/step - loss: 0.1371 - accuracy: 0.9467 - val_loss: 0.3822 - val_accuracy: 0.8979 - lr: 4.0252e-06\n",
      "Epoch 206/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0377 - accuracy: 0.9933\n",
      "Epoch 206: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.0377 - accuracy: 0.9933 - val_loss: 0.4521 - val_accuracy: 0.8919 - lr: 4.0252e-06\n",
      "Epoch 207/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1628 - accuracy: 0.9467\n",
      "Epoch 207: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.1628 - accuracy: 0.9467 - val_loss: 0.4123 - val_accuracy: 0.8919 - lr: 4.0252e-06\n",
      "Epoch 208/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1058 - accuracy: 0.9667\n",
      "Epoch 208: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.1058 - accuracy: 0.9667 - val_loss: 0.3848 - val_accuracy: 0.8960 - lr: 4.0252e-06\n",
      "Epoch 209/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0442 - accuracy: 0.9933\n",
      "Epoch 209: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.0442 - accuracy: 0.9933 - val_loss: 0.4000 - val_accuracy: 0.8964 - lr: 4.0252e-06\n",
      "Epoch 210/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1338 - accuracy: 0.9600\n",
      "Epoch 210: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.1338 - accuracy: 0.9600 - val_loss: 0.4090 - val_accuracy: 0.8873 - lr: 4.0252e-06\n",
      "Epoch 211/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1640 - accuracy: 0.9333\n",
      "Epoch 211: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 790ms/step - loss: 0.1640 - accuracy: 0.9333 - val_loss: 0.4923 - val_accuracy: 0.8638 - lr: 4.0252e-06\n",
      "Epoch 212/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1767 - accuracy: 0.9600\n",
      "Epoch 212: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.1767 - accuracy: 0.9600 - val_loss: 0.4071 - val_accuracy: 0.8818 - lr: 4.0252e-06\n",
      "Epoch 213/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0640 - accuracy: 0.9667\n",
      "Epoch 213: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 791ms/step - loss: 0.0640 - accuracy: 0.9667 - val_loss: 0.4060 - val_accuracy: 0.8873 - lr: 4.0252e-06\n",
      "Epoch 214/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0590 - accuracy: 0.9800\n",
      "Epoch 214: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.0590 - accuracy: 0.9800 - val_loss: 0.4183 - val_accuracy: 0.8849 - lr: 4.0252e-06\n",
      "Epoch 215/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0728 - accuracy: 0.9667\n",
      "Epoch 215: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 790ms/step - loss: 0.0728 - accuracy: 0.9667 - val_loss: 0.3876 - val_accuracy: 0.8953 - lr: 4.0252e-06\n",
      "Epoch 216/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0836 - accuracy: 0.9667\n",
      "Epoch 216: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.0836 - accuracy: 0.9667 - val_loss: 0.3840 - val_accuracy: 0.8942 - lr: 4.0252e-06\n",
      "Epoch 217/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1101 - accuracy: 0.9600\n",
      "Epoch 217: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 791ms/step - loss: 0.1101 - accuracy: 0.9600 - val_loss: 0.4275 - val_accuracy: 0.8867 - lr: 4.0252e-06\n",
      "Epoch 218/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0790 - accuracy: 0.9733\n",
      "Epoch 218: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.0790 - accuracy: 0.9733 - val_loss: 0.4068 - val_accuracy: 0.8914 - lr: 4.0252e-06\n",
      "Epoch 219/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1359 - accuracy: 0.9600\n",
      "Epoch 219: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 791ms/step - loss: 0.1359 - accuracy: 0.9600 - val_loss: 0.3950 - val_accuracy: 0.8917 - lr: 4.0252e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 220/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1755 - accuracy: 0.9200\n",
      "Epoch 220: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.1755 - accuracy: 0.9200 - val_loss: 0.4156 - val_accuracy: 0.8808 - lr: 4.0252e-06\n",
      "Epoch 221/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1691 - accuracy: 0.9467\n",
      "Epoch 221: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 791ms/step - loss: 0.1691 - accuracy: 0.9467 - val_loss: 0.4207 - val_accuracy: 0.8773 - lr: 4.0252e-06\n",
      "Epoch 222/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0778 - accuracy: 0.9667\n",
      "Epoch 222: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.0778 - accuracy: 0.9667 - val_loss: 0.5186 - val_accuracy: 0.8747 - lr: 4.0252e-06\n",
      "Epoch 223/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1296 - accuracy: 0.9600\n",
      "Epoch 223: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.1296 - accuracy: 0.9600 - val_loss: 0.4342 - val_accuracy: 0.8798 - lr: 4.0252e-06\n",
      "Epoch 224/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0901 - accuracy: 0.9600\n",
      "Epoch 224: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.0901 - accuracy: 0.9600 - val_loss: 0.4489 - val_accuracy: 0.8849 - lr: 4.0252e-06\n",
      "Epoch 225/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0979 - accuracy: 0.9733\n",
      "Epoch 225: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.0979 - accuracy: 0.9733 - val_loss: 0.3967 - val_accuracy: 0.8931 - lr: 4.0252e-06\n",
      "Epoch 226/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1577 - accuracy: 0.9533\n",
      "Epoch 226: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.1577 - accuracy: 0.9533 - val_loss: 0.4149 - val_accuracy: 0.8854 - lr: 4.0252e-06\n",
      "Epoch 227/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0646 - accuracy: 0.9733\n",
      "Epoch 227: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 791ms/step - loss: 0.0646 - accuracy: 0.9733 - val_loss: 0.4099 - val_accuracy: 0.8893 - lr: 4.0252e-06\n",
      "Epoch 228/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1318 - accuracy: 0.9467\n",
      "Epoch 228: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.1318 - accuracy: 0.9467 - val_loss: 0.3867 - val_accuracy: 0.8978 - lr: 4.0252e-06\n",
      "Epoch 229/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1278 - accuracy: 0.9600\n",
      "Epoch 229: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.1278 - accuracy: 0.9600 - val_loss: 0.3653 - val_accuracy: 0.8966 - lr: 4.0252e-06\n",
      "Epoch 230/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1732 - accuracy: 0.9600\n",
      "Epoch 230: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.1732 - accuracy: 0.9600 - val_loss: 0.3514 - val_accuracy: 0.8962 - lr: 4.0252e-06\n",
      "Epoch 231/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0767 - accuracy: 0.9733\n",
      "Epoch 231: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.0767 - accuracy: 0.9733 - val_loss: 0.3771 - val_accuracy: 0.8954 - lr: 4.0252e-06\n",
      "Epoch 232/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0799 - accuracy: 0.9667\n",
      "Epoch 232: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.0799 - accuracy: 0.9667 - val_loss: 0.4107 - val_accuracy: 0.8896 - lr: 4.0252e-06\n",
      "Epoch 233/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1655 - accuracy: 0.9533\n",
      "Epoch 233: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.1655 - accuracy: 0.9533 - val_loss: 0.3832 - val_accuracy: 0.8909 - lr: 4.0252e-06\n",
      "Epoch 234/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1178 - accuracy: 0.9533\n",
      "Epoch 234: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.1178 - accuracy: 0.9533 - val_loss: 0.3947 - val_accuracy: 0.8888 - lr: 4.0252e-06\n",
      "Epoch 235/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1523 - accuracy: 0.9400\n",
      "Epoch 235: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.1523 - accuracy: 0.9400 - val_loss: 0.4551 - val_accuracy: 0.8701 - lr: 4.0252e-06\n",
      "Epoch 236/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0786 - accuracy: 0.9667\n",
      "Epoch 236: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.0786 - accuracy: 0.9667 - val_loss: 0.3809 - val_accuracy: 0.8945 - lr: 4.0252e-06\n",
      "Epoch 237/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1832 - accuracy: 0.9333\n",
      "Epoch 237: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.1832 - accuracy: 0.9333 - val_loss: 0.4041 - val_accuracy: 0.8861 - lr: 4.0252e-06\n",
      "Epoch 238/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1677 - accuracy: 0.9400\n",
      "Epoch 238: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.1677 - accuracy: 0.9400 - val_loss: 0.3873 - val_accuracy: 0.8829 - lr: 4.0252e-06\n",
      "Epoch 239/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1034 - accuracy: 0.9733\n",
      "Epoch 239: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.1034 - accuracy: 0.9733 - val_loss: 0.3784 - val_accuracy: 0.8950 - lr: 4.0252e-06\n",
      "Epoch 240/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0902 - accuracy: 0.9667\n",
      "Epoch 240: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.0902 - accuracy: 0.9667 - val_loss: 0.3654 - val_accuracy: 0.9029 - lr: 4.0252e-06\n",
      "Epoch 241/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1178 - accuracy: 0.9600\n",
      "Epoch 241: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.1178 - accuracy: 0.9600 - val_loss: 0.3870 - val_accuracy: 0.8990 - lr: 4.0252e-06\n",
      "Epoch 242/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1672 - accuracy: 0.9533\n",
      "Epoch 242: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.1672 - accuracy: 0.9533 - val_loss: 0.3744 - val_accuracy: 0.8876 - lr: 4.0252e-06\n",
      "Epoch 243/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1200 - accuracy: 0.9733\n",
      "Epoch 243: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.1200 - accuracy: 0.9733 - val_loss: 0.3471 - val_accuracy: 0.9017 - lr: 4.0252e-06\n",
      "Epoch 244/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0928 - accuracy: 0.9733\n",
      "Epoch 244: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.0928 - accuracy: 0.9733 - val_loss: 0.3518 - val_accuracy: 0.8963 - lr: 4.0252e-06\n",
      "Epoch 245/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1051 - accuracy: 0.9800\n",
      "Epoch 245: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.1051 - accuracy: 0.9800 - val_loss: 0.3896 - val_accuracy: 0.8964 - lr: 4.0252e-06\n",
      "Epoch 246/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1069 - accuracy: 0.9667\n",
      "Epoch 246: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.1069 - accuracy: 0.9667 - val_loss: 0.3889 - val_accuracy: 0.8935 - lr: 4.0252e-06\n",
      "Epoch 247/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0993 - accuracy: 0.9667\n",
      "Epoch 247: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.0993 - accuracy: 0.9667 - val_loss: 0.4403 - val_accuracy: 0.8866 - lr: 4.0252e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 248/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1148 - accuracy: 0.9667\n",
      "Epoch 248: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.1148 - accuracy: 0.9667 - val_loss: 0.3917 - val_accuracy: 0.8931 - lr: 4.0252e-06\n",
      "Epoch 249/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1291 - accuracy: 0.9467\n",
      "Epoch 249: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.1291 - accuracy: 0.9467 - val_loss: 0.4316 - val_accuracy: 0.8753 - lr: 4.0252e-06\n",
      "Epoch 250/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0471 - accuracy: 0.9867\n",
      "Epoch 250: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.0471 - accuracy: 0.9867 - val_loss: 0.4170 - val_accuracy: 0.8897 - lr: 4.0252e-06\n",
      "Epoch 251/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0713 - accuracy: 0.9800\n",
      "Epoch 251: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.0713 - accuracy: 0.9800 - val_loss: 0.3454 - val_accuracy: 0.9014 - lr: 4.0252e-06\n",
      "Epoch 252/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1345 - accuracy: 0.9667\n",
      "Epoch 252: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.1345 - accuracy: 0.9667 - val_loss: 0.3568 - val_accuracy: 0.9011 - lr: 4.0252e-06\n",
      "Epoch 253/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1242 - accuracy: 0.9667\n",
      "Epoch 253: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.1242 - accuracy: 0.9667 - val_loss: 0.3424 - val_accuracy: 0.9036 - lr: 4.0252e-06\n",
      "Epoch 254/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1193 - accuracy: 0.9667\n",
      "Epoch 254: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.1193 - accuracy: 0.9667 - val_loss: 0.3505 - val_accuracy: 0.8977 - lr: 4.0252e-06\n",
      "Epoch 255/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.2288 - accuracy: 0.9333\n",
      "Epoch 255: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.2288 - accuracy: 0.9333 - val_loss: 0.3368 - val_accuracy: 0.8998 - lr: 4.0252e-06\n",
      "Epoch 256/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0624 - accuracy: 0.9800\n",
      "Epoch 256: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.0624 - accuracy: 0.9800 - val_loss: 0.3915 - val_accuracy: 0.8914 - lr: 4.0252e-06\n",
      "Epoch 257/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0432 - accuracy: 0.9800\n",
      "Epoch 257: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.0432 - accuracy: 0.9800 - val_loss: 0.4334 - val_accuracy: 0.8899 - lr: 4.0252e-06\n",
      "Epoch 258/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0478 - accuracy: 0.9867\n",
      "Epoch 258: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.0478 - accuracy: 0.9867 - val_loss: 0.3662 - val_accuracy: 0.8996 - lr: 4.0252e-06\n",
      "Epoch 259/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0650 - accuracy: 0.9733\n",
      "Epoch 259: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.0650 - accuracy: 0.9733 - val_loss: 0.4845 - val_accuracy: 0.8789 - lr: 4.0252e-06\n",
      "Epoch 260/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.2184 - accuracy: 0.9200\n",
      "Epoch 260: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 797ms/step - loss: 0.2184 - accuracy: 0.9200 - val_loss: 0.4133 - val_accuracy: 0.8832 - lr: 4.0252e-06\n",
      "Epoch 261/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1855 - accuracy: 0.9333\n",
      "Epoch 261: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.1855 - accuracy: 0.9333 - val_loss: 0.3863 - val_accuracy: 0.8904 - lr: 4.0252e-06\n",
      "Epoch 262/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0923 - accuracy: 0.9733\n",
      "Epoch 262: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.0923 - accuracy: 0.9733 - val_loss: 0.3680 - val_accuracy: 0.8980 - lr: 4.0252e-06\n",
      "Epoch 263/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0613 - accuracy: 0.9800\n",
      "Epoch 263: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.0613 - accuracy: 0.9800 - val_loss: 0.3694 - val_accuracy: 0.8995 - lr: 4.0252e-06\n",
      "Epoch 264/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0966 - accuracy: 0.9533\n",
      "Epoch 264: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.0966 - accuracy: 0.9533 - val_loss: 0.4100 - val_accuracy: 0.8915 - lr: 4.0252e-06\n",
      "Epoch 265/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1034 - accuracy: 0.9600\n",
      "Epoch 265: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.1034 - accuracy: 0.9600 - val_loss: 0.3420 - val_accuracy: 0.9055 - lr: 4.0252e-06\n",
      "Epoch 266/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1223 - accuracy: 0.9667\n",
      "Epoch 266: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.1223 - accuracy: 0.9667 - val_loss: 0.3526 - val_accuracy: 0.9011 - lr: 4.0252e-06\n",
      "Epoch 267/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1258 - accuracy: 0.9600\n",
      "Epoch 267: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.1258 - accuracy: 0.9600 - val_loss: 0.4038 - val_accuracy: 0.8890 - lr: 4.0252e-06\n",
      "Epoch 268/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1473 - accuracy: 0.9467\n",
      "Epoch 268: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.1473 - accuracy: 0.9467 - val_loss: 0.3967 - val_accuracy: 0.8839 - lr: 4.0252e-06\n",
      "Epoch 269/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1094 - accuracy: 0.9467\n",
      "Epoch 269: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.1094 - accuracy: 0.9467 - val_loss: 0.3508 - val_accuracy: 0.9018 - lr: 4.0252e-06\n",
      "Epoch 270/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1331 - accuracy: 0.9533\n",
      "Epoch 270: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.1331 - accuracy: 0.9533 - val_loss: 0.3503 - val_accuracy: 0.9012 - lr: 4.0252e-06\n",
      "Epoch 271/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0972 - accuracy: 0.9600\n",
      "Epoch 271: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.0972 - accuracy: 0.9600 - val_loss: 0.4109 - val_accuracy: 0.8926 - lr: 4.0252e-06\n",
      "Epoch 272/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0897 - accuracy: 0.9667\n",
      "Epoch 272: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.0897 - accuracy: 0.9667 - val_loss: 0.4848 - val_accuracy: 0.8870 - lr: 4.0252e-06\n",
      "Epoch 273/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1339 - accuracy: 0.9400\n",
      "Epoch 273: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.1339 - accuracy: 0.9400 - val_loss: 0.4000 - val_accuracy: 0.8922 - lr: 4.0252e-06\n",
      "Epoch 274/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1339 - accuracy: 0.9600\n",
      "Epoch 274: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.1339 - accuracy: 0.9600 - val_loss: 0.3642 - val_accuracy: 0.8990 - lr: 4.0252e-06\n",
      "Epoch 275/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0682 - accuracy: 0.9800\n",
      "Epoch 275: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.0682 - accuracy: 0.9800 - val_loss: 0.4314 - val_accuracy: 0.8876 - lr: 4.0252e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 276/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.2044 - accuracy: 0.9400\n",
      "Epoch 276: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.2044 - accuracy: 0.9400 - val_loss: 0.5027 - val_accuracy: 0.8765 - lr: 4.0252e-06\n",
      "Epoch 277/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0972 - accuracy: 0.9867\n",
      "Epoch 277: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.0972 - accuracy: 0.9867 - val_loss: 0.4360 - val_accuracy: 0.8847 - lr: 4.0252e-06\n",
      "Epoch 278/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1187 - accuracy: 0.9600\n",
      "Epoch 278: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.1187 - accuracy: 0.9600 - val_loss: 0.3979 - val_accuracy: 0.8921 - lr: 4.0252e-06\n",
      "Epoch 279/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0852 - accuracy: 0.9800\n",
      "Epoch 279: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.0852 - accuracy: 0.9800 - val_loss: 0.4149 - val_accuracy: 0.8897 - lr: 4.0252e-06\n",
      "Epoch 280/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0457 - accuracy: 0.9800\n",
      "Epoch 280: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.0457 - accuracy: 0.9800 - val_loss: 0.4091 - val_accuracy: 0.8917 - lr: 4.0252e-06\n",
      "Epoch 281/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0211 - accuracy: 0.9933\n",
      "Epoch 281: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.0211 - accuracy: 0.9933 - val_loss: 0.4207 - val_accuracy: 0.8931 - lr: 4.0252e-06\n",
      "Epoch 282/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0633 - accuracy: 0.9800\n",
      "Epoch 282: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.0633 - accuracy: 0.9800 - val_loss: 0.4051 - val_accuracy: 0.8977 - lr: 4.0252e-06\n",
      "Epoch 283/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1191 - accuracy: 0.9600\n",
      "Epoch 283: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.1191 - accuracy: 0.9600 - val_loss: 0.4466 - val_accuracy: 0.8887 - lr: 4.0252e-06\n",
      "Epoch 284/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1151 - accuracy: 0.9733\n",
      "Epoch 284: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.1151 - accuracy: 0.9733 - val_loss: 0.4431 - val_accuracy: 0.8847 - lr: 4.0252e-06\n",
      "Epoch 285/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1256 - accuracy: 0.9533\n",
      "Epoch 285: val_loss did not improve from 0.33575\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.1256 - accuracy: 0.9533 - val_loss: 0.3942 - val_accuracy: 0.8907 - lr: 4.0252e-06\n",
      "Epoch 286/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1015 - accuracy: 0.9600\n",
      "Epoch 286: val_loss improved from 0.33575 to 0.32870, saving model to tf_TransferLearning_8Classes_best_model.hdf5\n",
      "75/75 [==============================] - 59s 798ms/step - loss: 0.1015 - accuracy: 0.9600 - val_loss: 0.3287 - val_accuracy: 0.9021 - lr: 4.0252e-06\n",
      "Epoch 287/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0789 - accuracy: 0.9733\n",
      "Epoch 287: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.0789 - accuracy: 0.9733 - val_loss: 0.3493 - val_accuracy: 0.8978 - lr: 4.0252e-06\n",
      "Epoch 288/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1137 - accuracy: 0.9667\n",
      "Epoch 288: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.1137 - accuracy: 0.9667 - val_loss: 0.3418 - val_accuracy: 0.9014 - lr: 4.0252e-06\n",
      "Epoch 289/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0908 - accuracy: 0.9667\n",
      "Epoch 289: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.0908 - accuracy: 0.9667 - val_loss: 0.3573 - val_accuracy: 0.9024 - lr: 4.0252e-06\n",
      "Epoch 290/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0878 - accuracy: 0.9667\n",
      "Epoch 290: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.0878 - accuracy: 0.9667 - val_loss: 0.4042 - val_accuracy: 0.8942 - lr: 4.0252e-06\n",
      "Epoch 291/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1352 - accuracy: 0.9667\n",
      "Epoch 291: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.1352 - accuracy: 0.9667 - val_loss: 0.4176 - val_accuracy: 0.8874 - lr: 4.0252e-06\n",
      "Epoch 292/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0882 - accuracy: 0.9533\n",
      "Epoch 292: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.0882 - accuracy: 0.9533 - val_loss: 0.5279 - val_accuracy: 0.8797 - lr: 4.0252e-06\n",
      "Epoch 293/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1186 - accuracy: 0.9533\n",
      "Epoch 293: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.1186 - accuracy: 0.9533 - val_loss: 0.3457 - val_accuracy: 0.9031 - lr: 4.0252e-06\n",
      "Epoch 294/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1093 - accuracy: 0.9733\n",
      "Epoch 294: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.1093 - accuracy: 0.9733 - val_loss: 0.3632 - val_accuracy: 0.9026 - lr: 4.0252e-06\n",
      "Epoch 295/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1302 - accuracy: 0.9733\n",
      "Epoch 295: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.1302 - accuracy: 0.9733 - val_loss: 0.3646 - val_accuracy: 0.9001 - lr: 4.0252e-06\n",
      "Epoch 296/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1644 - accuracy: 0.9533\n",
      "Epoch 296: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.1644 - accuracy: 0.9533 - val_loss: 0.3294 - val_accuracy: 0.9031 - lr: 4.0252e-06\n",
      "Epoch 297/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1231 - accuracy: 0.9533\n",
      "Epoch 297: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.1231 - accuracy: 0.9533 - val_loss: 0.3486 - val_accuracy: 0.8991 - lr: 4.0252e-06\n",
      "Epoch 298/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0603 - accuracy: 0.9799\n",
      "Epoch 298: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.0603 - accuracy: 0.9799 - val_loss: 0.3842 - val_accuracy: 0.8923 - lr: 4.0252e-06\n",
      "Epoch 299/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0709 - accuracy: 0.9800\n",
      "Epoch 299: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.0709 - accuracy: 0.9800 - val_loss: 0.3893 - val_accuracy: 0.8969 - lr: 4.0252e-06\n",
      "Epoch 300/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0928 - accuracy: 0.9800\n",
      "Epoch 300: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.0928 - accuracy: 0.9800 - val_loss: 0.4966 - val_accuracy: 0.8787 - lr: 4.0252e-06\n",
      "Epoch 301/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0603 - accuracy: 0.9733\n",
      "Epoch 301: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.0603 - accuracy: 0.9733 - val_loss: 0.4303 - val_accuracy: 0.8887 - lr: 4.0252e-06\n",
      "Epoch 302/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1825 - accuracy: 0.9400\n",
      "Epoch 302: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.1825 - accuracy: 0.9400 - val_loss: 0.5149 - val_accuracy: 0.8586 - lr: 4.0252e-06\n",
      "Epoch 303/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1626 - accuracy: 0.9400\n",
      "Epoch 303: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.1626 - accuracy: 0.9400 - val_loss: 0.3810 - val_accuracy: 0.8881 - lr: 4.0252e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 304/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0687 - accuracy: 0.9867\n",
      "Epoch 304: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.0687 - accuracy: 0.9867 - val_loss: 0.3804 - val_accuracy: 0.8961 - lr: 4.0252e-06\n",
      "Epoch 305/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0806 - accuracy: 0.9733\n",
      "Epoch 305: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.0806 - accuracy: 0.9733 - val_loss: 0.4091 - val_accuracy: 0.8908 - lr: 4.0252e-06\n",
      "Epoch 306/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1854 - accuracy: 0.9133\n",
      "Epoch 306: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.1854 - accuracy: 0.9133 - val_loss: 0.4048 - val_accuracy: 0.8865 - lr: 4.0252e-06\n",
      "Epoch 307/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0790 - accuracy: 0.9733\n",
      "Epoch 307: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.0790 - accuracy: 0.9733 - val_loss: 0.3819 - val_accuracy: 0.9009 - lr: 4.0252e-06\n",
      "Epoch 308/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0778 - accuracy: 0.9867\n",
      "Epoch 308: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.0778 - accuracy: 0.9867 - val_loss: 0.4303 - val_accuracy: 0.8850 - lr: 4.0252e-06\n",
      "Epoch 309/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1150 - accuracy: 0.9533\n",
      "Epoch 309: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.1150 - accuracy: 0.9533 - val_loss: 0.4391 - val_accuracy: 0.8875 - lr: 4.0252e-06\n",
      "Epoch 310/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1057 - accuracy: 0.9600\n",
      "Epoch 310: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.1057 - accuracy: 0.9600 - val_loss: 0.4090 - val_accuracy: 0.8815 - lr: 4.0252e-06\n",
      "Epoch 311/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0860 - accuracy: 0.9600\n",
      "Epoch 311: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.0860 - accuracy: 0.9600 - val_loss: 0.4242 - val_accuracy: 0.8885 - lr: 4.0252e-06\n",
      "Epoch 312/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0868 - accuracy: 0.9667\n",
      "Epoch 312: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.0868 - accuracy: 0.9667 - val_loss: 0.4106 - val_accuracy: 0.8922 - lr: 4.0252e-06\n",
      "Epoch 313/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0506 - accuracy: 0.9867\n",
      "Epoch 313: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.0506 - accuracy: 0.9867 - val_loss: 0.4799 - val_accuracy: 0.8891 - lr: 4.0252e-06\n",
      "Epoch 314/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0600 - accuracy: 0.9733\n",
      "Epoch 314: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.0600 - accuracy: 0.9733 - val_loss: 0.5089 - val_accuracy: 0.8724 - lr: 4.0252e-06\n",
      "Epoch 315/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1612 - accuracy: 0.9733\n",
      "Epoch 315: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.1612 - accuracy: 0.9733 - val_loss: 0.3789 - val_accuracy: 0.8905 - lr: 4.0252e-06\n",
      "Epoch 316/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0541 - accuracy: 0.9867\n",
      "Epoch 316: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.0541 - accuracy: 0.9867 - val_loss: 0.4040 - val_accuracy: 0.8932 - lr: 4.0252e-06\n",
      "Epoch 317/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0706 - accuracy: 0.9667\n",
      "Epoch 317: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.0706 - accuracy: 0.9667 - val_loss: 0.4230 - val_accuracy: 0.8892 - lr: 4.0252e-06\n",
      "Epoch 318/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0725 - accuracy: 0.9667\n",
      "Epoch 318: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.0725 - accuracy: 0.9667 - val_loss: 0.4132 - val_accuracy: 0.8947 - lr: 4.0252e-06\n",
      "Epoch 319/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0652 - accuracy: 0.9867\n",
      "Epoch 319: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.0652 - accuracy: 0.9867 - val_loss: 0.3975 - val_accuracy: 0.8928 - lr: 4.0252e-06\n",
      "Epoch 320/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0998 - accuracy: 0.9800\n",
      "Epoch 320: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.0998 - accuracy: 0.9800 - val_loss: 0.3661 - val_accuracy: 0.8961 - lr: 4.0252e-06\n",
      "Epoch 321/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0580 - accuracy: 0.9800\n",
      "Epoch 321: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.0580 - accuracy: 0.9800 - val_loss: 0.3986 - val_accuracy: 0.8929 - lr: 4.0252e-06\n",
      "Epoch 322/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1124 - accuracy: 0.9667\n",
      "Epoch 322: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.1124 - accuracy: 0.9667 - val_loss: 0.3642 - val_accuracy: 0.9014 - lr: 4.0252e-06\n",
      "Epoch 323/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1244 - accuracy: 0.9600\n",
      "Epoch 323: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.1244 - accuracy: 0.9600 - val_loss: 0.3851 - val_accuracy: 0.9007 - lr: 4.0252e-06\n",
      "Epoch 324/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1215 - accuracy: 0.9667\n",
      "Epoch 324: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.1215 - accuracy: 0.9667 - val_loss: 0.3403 - val_accuracy: 0.9043 - lr: 4.0252e-06\n",
      "Epoch 325/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1663 - accuracy: 0.9733\n",
      "Epoch 325: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.1663 - accuracy: 0.9733 - val_loss: 0.3771 - val_accuracy: 0.8961 - lr: 4.0252e-06\n",
      "Epoch 326/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0707 - accuracy: 0.9733\n",
      "Epoch 326: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.0707 - accuracy: 0.9733 - val_loss: 0.3630 - val_accuracy: 0.9048 - lr: 4.0252e-06\n",
      "Epoch 327/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0972 - accuracy: 0.9600\n",
      "Epoch 327: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.0972 - accuracy: 0.9600 - val_loss: 0.3655 - val_accuracy: 0.9026 - lr: 4.0252e-06\n",
      "Epoch 328/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0520 - accuracy: 0.9867\n",
      "Epoch 328: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.0520 - accuracy: 0.9867 - val_loss: 0.3868 - val_accuracy: 0.9005 - lr: 4.0252e-06\n",
      "Epoch 329/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0692 - accuracy: 0.9800\n",
      "Epoch 329: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.0692 - accuracy: 0.9800 - val_loss: 0.3624 - val_accuracy: 0.9030 - lr: 4.0252e-06\n",
      "Epoch 330/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0653 - accuracy: 0.9800\n",
      "Epoch 330: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.0653 - accuracy: 0.9800 - val_loss: 0.4314 - val_accuracy: 0.8954 - lr: 4.0252e-06\n",
      "Epoch 331/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0592 - accuracy: 0.9800\n",
      "Epoch 331: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.0592 - accuracy: 0.9800 - val_loss: 0.4906 - val_accuracy: 0.8892 - lr: 4.0252e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 332/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1681 - accuracy: 0.9400\n",
      "Epoch 332: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.1681 - accuracy: 0.9400 - val_loss: 0.3928 - val_accuracy: 0.8970 - lr: 4.0252e-06\n",
      "Epoch 333/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0358 - accuracy: 0.9867\n",
      "Epoch 333: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.0358 - accuracy: 0.9867 - val_loss: 0.4147 - val_accuracy: 0.8959 - lr: 4.0252e-06\n",
      "Epoch 334/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1496 - accuracy: 0.9667\n",
      "Epoch 334: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.1496 - accuracy: 0.9667 - val_loss: 0.3574 - val_accuracy: 0.9008 - lr: 4.0252e-06\n",
      "Epoch 335/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1145 - accuracy: 0.9667\n",
      "Epoch 335: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.1145 - accuracy: 0.9667 - val_loss: 0.3702 - val_accuracy: 0.9017 - lr: 4.0252e-06\n",
      "Epoch 336/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0637 - accuracy: 0.9800\n",
      "Epoch 336: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.0637 - accuracy: 0.9800 - val_loss: 0.4020 - val_accuracy: 0.9026 - lr: 4.0252e-06\n",
      "Epoch 337/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1641 - accuracy: 0.9467\n",
      "Epoch 337: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.1641 - accuracy: 0.9467 - val_loss: 0.4542 - val_accuracy: 0.8882 - lr: 4.0252e-06\n",
      "Epoch 338/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1291 - accuracy: 0.9400\n",
      "Epoch 338: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.1291 - accuracy: 0.9400 - val_loss: 0.3964 - val_accuracy: 0.9022 - lr: 4.0252e-06\n",
      "Epoch 339/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1616 - accuracy: 0.9400\n",
      "Epoch 339: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.1616 - accuracy: 0.9400 - val_loss: 0.3611 - val_accuracy: 0.9003 - lr: 4.0252e-06\n",
      "Epoch 340/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1320 - accuracy: 0.9533\n",
      "Epoch 340: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.1320 - accuracy: 0.9533 - val_loss: 0.4515 - val_accuracy: 0.8758 - lr: 4.0252e-06\n",
      "Epoch 341/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1381 - accuracy: 0.9467\n",
      "Epoch 341: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.1381 - accuracy: 0.9467 - val_loss: 0.3625 - val_accuracy: 0.9016 - lr: 4.0252e-06\n",
      "Epoch 342/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0345 - accuracy: 0.9933\n",
      "Epoch 342: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.0345 - accuracy: 0.9933 - val_loss: 0.3628 - val_accuracy: 0.9048 - lr: 4.0252e-06\n",
      "Epoch 343/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1820 - accuracy: 0.9467\n",
      "Epoch 343: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.1820 - accuracy: 0.9467 - val_loss: 0.3837 - val_accuracy: 0.8947 - lr: 4.0252e-06\n",
      "Epoch 344/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1268 - accuracy: 0.9267\n",
      "Epoch 344: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.1268 - accuracy: 0.9267 - val_loss: 0.3657 - val_accuracy: 0.8971 - lr: 4.0252e-06\n",
      "Epoch 345/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0373 - accuracy: 1.0000\n",
      "Epoch 345: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.0373 - accuracy: 1.0000 - val_loss: 0.3564 - val_accuracy: 0.9026 - lr: 4.0252e-06\n",
      "Epoch 346/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0933 - accuracy: 0.9733\n",
      "Epoch 346: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.0933 - accuracy: 0.9733 - val_loss: 0.3382 - val_accuracy: 0.9036 - lr: 4.0252e-06\n",
      "Epoch 347/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1444 - accuracy: 0.9467\n",
      "Epoch 347: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.1444 - accuracy: 0.9467 - val_loss: 0.4424 - val_accuracy: 0.8847 - lr: 4.0252e-06\n",
      "Epoch 348/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1442 - accuracy: 0.9533\n",
      "Epoch 348: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.1442 - accuracy: 0.9533 - val_loss: 0.3457 - val_accuracy: 0.8969 - lr: 4.0252e-06\n",
      "Epoch 349/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0509 - accuracy: 0.9933\n",
      "Epoch 349: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.0509 - accuracy: 0.9933 - val_loss: 0.3426 - val_accuracy: 0.9021 - lr: 4.0252e-06\n",
      "Epoch 350/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0316 - accuracy: 0.9933\n",
      "Epoch 350: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.0316 - accuracy: 0.9933 - val_loss: 0.3544 - val_accuracy: 0.9029 - lr: 4.0252e-06\n",
      "Epoch 351/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0416 - accuracy: 0.9867\n",
      "Epoch 351: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.0416 - accuracy: 0.9867 - val_loss: 0.4725 - val_accuracy: 0.8728 - lr: 4.0252e-06\n",
      "Epoch 352/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1000 - accuracy: 0.9600\n",
      "Epoch 352: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.1000 - accuracy: 0.9600 - val_loss: 0.3536 - val_accuracy: 0.9039 - lr: 4.0252e-06\n",
      "Epoch 353/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0633 - accuracy: 0.9733\n",
      "Epoch 353: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.0633 - accuracy: 0.9733 - val_loss: 0.4766 - val_accuracy: 0.8897 - lr: 4.0252e-06\n",
      "Epoch 354/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1084 - accuracy: 0.9800\n",
      "Epoch 354: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.1084 - accuracy: 0.9800 - val_loss: 0.3721 - val_accuracy: 0.8956 - lr: 4.0252e-06\n",
      "Epoch 355/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0470 - accuracy: 0.9867\n",
      "Epoch 355: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.0470 - accuracy: 0.9867 - val_loss: 0.3602 - val_accuracy: 0.9002 - lr: 4.0252e-06\n",
      "Epoch 356/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0843 - accuracy: 0.9800\n",
      "Epoch 356: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.0843 - accuracy: 0.9800 - val_loss: 0.3596 - val_accuracy: 0.8997 - lr: 4.0252e-06\n",
      "Epoch 357/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0867 - accuracy: 0.9667\n",
      "Epoch 357: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.0867 - accuracy: 0.9667 - val_loss: 0.3564 - val_accuracy: 0.9017 - lr: 4.0252e-06\n",
      "Epoch 358/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0513 - accuracy: 0.9800\n",
      "Epoch 358: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.0513 - accuracy: 0.9800 - val_loss: 0.4470 - val_accuracy: 0.8944 - lr: 4.0252e-06\n",
      "Epoch 359/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1172 - accuracy: 0.9733\n",
      "Epoch 359: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.1172 - accuracy: 0.9733 - val_loss: 0.4170 - val_accuracy: 0.8952 - lr: 4.0252e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 360/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0396 - accuracy: 0.9867\n",
      "Epoch 360: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.0396 - accuracy: 0.9867 - val_loss: 0.4311 - val_accuracy: 0.8909 - lr: 4.0252e-06\n",
      "Epoch 361/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0629 - accuracy: 0.9867\n",
      "Epoch 361: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.0629 - accuracy: 0.9867 - val_loss: 0.5133 - val_accuracy: 0.8871 - lr: 4.0252e-06\n",
      "Epoch 362/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0485 - accuracy: 0.9667\n",
      "Epoch 362: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 797ms/step - loss: 0.0485 - accuracy: 0.9667 - val_loss: 0.4457 - val_accuracy: 0.8958 - lr: 4.0252e-06\n",
      "Epoch 363/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0656 - accuracy: 0.9600\n",
      "Epoch 363: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.0656 - accuracy: 0.9600 - val_loss: 0.4134 - val_accuracy: 0.8977 - lr: 4.0252e-06\n",
      "Epoch 364/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1414 - accuracy: 0.9533\n",
      "Epoch 364: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.1414 - accuracy: 0.9533 - val_loss: 0.3789 - val_accuracy: 0.8990 - lr: 4.0252e-06\n",
      "Epoch 365/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1118 - accuracy: 0.9533\n",
      "Epoch 365: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.1118 - accuracy: 0.9533 - val_loss: 0.4341 - val_accuracy: 0.9010 - lr: 4.0252e-06\n",
      "Epoch 366/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0447 - accuracy: 0.9867\n",
      "Epoch 366: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.0447 - accuracy: 0.9867 - val_loss: 0.3693 - val_accuracy: 0.9083 - lr: 4.0252e-06\n",
      "Epoch 367/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0954 - accuracy: 0.9667\n",
      "Epoch 367: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.0954 - accuracy: 0.9667 - val_loss: 0.3473 - val_accuracy: 0.9075 - lr: 4.0252e-06\n",
      "Epoch 368/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0807 - accuracy: 0.9667\n",
      "Epoch 368: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.0807 - accuracy: 0.9667 - val_loss: 0.3577 - val_accuracy: 0.9084 - lr: 4.0252e-06\n",
      "Epoch 369/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0686 - accuracy: 0.9733\n",
      "Epoch 369: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.0686 - accuracy: 0.9733 - val_loss: 0.3806 - val_accuracy: 0.9007 - lr: 4.0252e-06\n",
      "Epoch 370/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0321 - accuracy: 0.9867\n",
      "Epoch 370: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.0321 - accuracy: 0.9867 - val_loss: 0.3689 - val_accuracy: 0.9072 - lr: 4.0252e-06\n",
      "Epoch 371/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0583 - accuracy: 0.9933\n",
      "Epoch 371: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.0583 - accuracy: 0.9933 - val_loss: 0.3683 - val_accuracy: 0.9048 - lr: 4.0252e-06\n",
      "Epoch 372/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0991 - accuracy: 0.9733\n",
      "Epoch 372: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.0991 - accuracy: 0.9733 - val_loss: 0.4034 - val_accuracy: 0.9008 - lr: 4.0252e-06\n",
      "Epoch 373/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0675 - accuracy: 0.9800\n",
      "Epoch 373: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.0675 - accuracy: 0.9800 - val_loss: 0.5067 - val_accuracy: 0.8826 - lr: 4.0252e-06\n",
      "Epoch 374/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1156 - accuracy: 0.9667\n",
      "Epoch 374: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.1156 - accuracy: 0.9667 - val_loss: 0.4356 - val_accuracy: 0.8898 - lr: 4.0252e-06\n",
      "Epoch 375/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0417 - accuracy: 0.9867\n",
      "Epoch 375: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.0417 - accuracy: 0.9867 - val_loss: 0.3893 - val_accuracy: 0.8981 - lr: 4.0252e-06\n",
      "Epoch 376/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0792 - accuracy: 0.9733\n",
      "Epoch 376: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.0792 - accuracy: 0.9733 - val_loss: 0.4264 - val_accuracy: 0.8955 - lr: 4.0252e-06\n",
      "Epoch 377/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0428 - accuracy: 0.9867\n",
      "Epoch 377: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.0428 - accuracy: 0.9867 - val_loss: 0.4324 - val_accuracy: 0.8935 - lr: 4.0252e-06\n",
      "Epoch 378/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0213 - accuracy: 1.0000\n",
      "Epoch 378: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 0.4293 - val_accuracy: 0.8956 - lr: 4.0252e-06\n",
      "Epoch 379/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0319 - accuracy: 0.9867\n",
      "Epoch 379: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.0319 - accuracy: 0.9867 - val_loss: 0.5294 - val_accuracy: 0.8873 - lr: 4.0252e-06\n",
      "Epoch 380/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1032 - accuracy: 0.9733\n",
      "Epoch 380: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.1032 - accuracy: 0.9733 - val_loss: 0.4077 - val_accuracy: 0.9012 - lr: 4.0252e-06\n",
      "Epoch 381/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0332 - accuracy: 0.9867\n",
      "Epoch 381: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.0332 - accuracy: 0.9867 - val_loss: 0.4347 - val_accuracy: 0.8959 - lr: 4.0252e-06\n",
      "Epoch 382/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0209 - accuracy: 0.9933\n",
      "Epoch 382: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.0209 - accuracy: 0.9933 - val_loss: 0.4423 - val_accuracy: 0.8960 - lr: 4.0252e-06\n",
      "Epoch 383/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0712 - accuracy: 0.9733\n",
      "Epoch 383: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.0712 - accuracy: 0.9733 - val_loss: 0.3889 - val_accuracy: 0.9046 - lr: 4.0252e-06\n",
      "Epoch 384/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1131 - accuracy: 0.9600\n",
      "Epoch 384: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.1131 - accuracy: 0.9600 - val_loss: 0.3990 - val_accuracy: 0.8907 - lr: 4.0252e-06\n",
      "Epoch 385/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0910 - accuracy: 0.9733\n",
      "Epoch 385: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.0910 - accuracy: 0.9733 - val_loss: 0.4354 - val_accuracy: 0.8828 - lr: 4.0252e-06\n",
      "Epoch 386/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0731 - accuracy: 0.9667\n",
      "Epoch 386: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.0731 - accuracy: 0.9667 - val_loss: 0.4896 - val_accuracy: 0.8709 - lr: 4.0252e-06\n",
      "Epoch 387/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1355 - accuracy: 0.9533\n",
      "Epoch 387: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.1355 - accuracy: 0.9533 - val_loss: 0.4471 - val_accuracy: 0.8917 - lr: 4.0252e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 388/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1264 - accuracy: 0.9467\n",
      "Epoch 388: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.1264 - accuracy: 0.9467 - val_loss: 0.3497 - val_accuracy: 0.8992 - lr: 4.0252e-06\n",
      "Epoch 389/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1047 - accuracy: 0.9667\n",
      "Epoch 389: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.1047 - accuracy: 0.9667 - val_loss: 0.3426 - val_accuracy: 0.8983 - lr: 4.0252e-06\n",
      "Epoch 390/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0934 - accuracy: 0.9600\n",
      "Epoch 390: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.0934 - accuracy: 0.9600 - val_loss: 0.3728 - val_accuracy: 0.8983 - lr: 4.0252e-06\n",
      "Epoch 391/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0245 - accuracy: 1.0000\n",
      "Epoch 391: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.0245 - accuracy: 1.0000 - val_loss: 0.3612 - val_accuracy: 0.8986 - lr: 4.0252e-06\n",
      "Epoch 392/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0147 - accuracy: 1.0000\n",
      "Epoch 392: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 797ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.3626 - val_accuracy: 0.8997 - lr: 4.0252e-06\n",
      "Epoch 393/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0647 - accuracy: 0.9867\n",
      "Epoch 393: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.0647 - accuracy: 0.9867 - val_loss: 0.3716 - val_accuracy: 0.9013 - lr: 4.0252e-06\n",
      "Epoch 394/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0756 - accuracy: 0.9733\n",
      "Epoch 394: val_loss did not improve from 0.32870\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.0756 - accuracy: 0.9733 - val_loss: 0.3739 - val_accuracy: 0.9050 - lr: 4.0252e-06\n",
      "Epoch 395/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0602 - accuracy: 0.9933\n",
      "Epoch 395: val_loss improved from 0.32870 to 0.32644, saving model to tf_TransferLearning_8Classes_best_model.hdf5\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.0602 - accuracy: 0.9933 - val_loss: 0.3264 - val_accuracy: 0.9116 - lr: 4.0252e-06\n",
      "Epoch 396/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0763 - accuracy: 0.9933\n",
      "Epoch 396: val_loss did not improve from 0.32644\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.0763 - accuracy: 0.9933 - val_loss: 0.3304 - val_accuracy: 0.9093 - lr: 4.0252e-06\n",
      "Epoch 397/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0920 - accuracy: 0.9733\n",
      "Epoch 397: val_loss did not improve from 0.32644\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.0920 - accuracy: 0.9733 - val_loss: 0.3344 - val_accuracy: 0.9118 - lr: 4.0252e-06\n",
      "Epoch 398/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0697 - accuracy: 0.9733\n",
      "Epoch 398: val_loss did not improve from 0.32644\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.0697 - accuracy: 0.9733 - val_loss: 0.3509 - val_accuracy: 0.9076 - lr: 4.0252e-06\n",
      "Epoch 399/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1595 - accuracy: 0.9467\n",
      "Epoch 399: val_loss improved from 0.32644 to 0.32161, saving model to tf_TransferLearning_8Classes_best_model.hdf5\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.1595 - accuracy: 0.9467 - val_loss: 0.3216 - val_accuracy: 0.9101 - lr: 4.0252e-06\n",
      "Epoch 400/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1369 - accuracy: 0.9600\n",
      "Epoch 400: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.1369 - accuracy: 0.9600 - val_loss: 0.3685 - val_accuracy: 0.8950 - lr: 4.0252e-06\n",
      "Epoch 401/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0655 - accuracy: 0.9867\n",
      "Epoch 401: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.0655 - accuracy: 0.9867 - val_loss: 0.3617 - val_accuracy: 0.8963 - lr: 4.0252e-06\n",
      "Epoch 402/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1100 - accuracy: 0.9600\n",
      "Epoch 402: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.1100 - accuracy: 0.9600 - val_loss: 0.3544 - val_accuracy: 0.8981 - lr: 4.0252e-06\n",
      "Epoch 403/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0624 - accuracy: 0.9733\n",
      "Epoch 403: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.0624 - accuracy: 0.9733 - val_loss: 0.4026 - val_accuracy: 0.8885 - lr: 4.0252e-06\n",
      "Epoch 404/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1214 - accuracy: 0.9600\n",
      "Epoch 404: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.1214 - accuracy: 0.9600 - val_loss: 0.3536 - val_accuracy: 0.8952 - lr: 4.0252e-06\n",
      "Epoch 405/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1548 - accuracy: 0.9600\n",
      "Epoch 405: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.1548 - accuracy: 0.9600 - val_loss: 0.3406 - val_accuracy: 0.8986 - lr: 4.0252e-06\n",
      "Epoch 406/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0663 - accuracy: 0.9733\n",
      "Epoch 406: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.0663 - accuracy: 0.9733 - val_loss: 0.3687 - val_accuracy: 0.9004 - lr: 4.0252e-06\n",
      "Epoch 407/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0609 - accuracy: 0.9867\n",
      "Epoch 407: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.0609 - accuracy: 0.9867 - val_loss: 0.3694 - val_accuracy: 0.9018 - lr: 4.0252e-06\n",
      "Epoch 408/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0990 - accuracy: 0.9733\n",
      "Epoch 408: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.0990 - accuracy: 0.9733 - val_loss: 0.3523 - val_accuracy: 0.9027 - lr: 4.0252e-06\n",
      "Epoch 409/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0358 - accuracy: 0.9933\n",
      "Epoch 409: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.0358 - accuracy: 0.9933 - val_loss: 0.3423 - val_accuracy: 0.9029 - lr: 4.0252e-06\n",
      "Epoch 410/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1016 - accuracy: 0.9800\n",
      "Epoch 410: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.1016 - accuracy: 0.9800 - val_loss: 0.3685 - val_accuracy: 0.9013 - lr: 4.0252e-06\n",
      "Epoch 411/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0320 - accuracy: 0.9800\n",
      "Epoch 411: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.0320 - accuracy: 0.9800 - val_loss: 0.3970 - val_accuracy: 0.9020 - lr: 4.0252e-06\n",
      "Epoch 412/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0286 - accuracy: 0.9933\n",
      "Epoch 412: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.0286 - accuracy: 0.9933 - val_loss: 0.4330 - val_accuracy: 0.9007 - lr: 4.0252e-06\n",
      "Epoch 413/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1486 - accuracy: 0.9600\n",
      "Epoch 413: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.1486 - accuracy: 0.9600 - val_loss: 0.6653 - val_accuracy: 0.8596 - lr: 4.0252e-06\n",
      "Epoch 414/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1319 - accuracy: 0.9600\n",
      "Epoch 414: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.1319 - accuracy: 0.9600 - val_loss: 0.5169 - val_accuracy: 0.8676 - lr: 4.0252e-06\n",
      "Epoch 415/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - ETA: 0s - loss: 0.1129 - accuracy: 0.9600\n",
      "Epoch 415: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.1129 - accuracy: 0.9600 - val_loss: 0.3962 - val_accuracy: 0.8947 - lr: 4.0252e-06\n",
      "Epoch 416/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1044 - accuracy: 0.9733\n",
      "Epoch 416: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.1044 - accuracy: 0.9733 - val_loss: 0.3576 - val_accuracy: 0.9010 - lr: 4.0252e-06\n",
      "Epoch 417/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0774 - accuracy: 0.9733\n",
      "Epoch 417: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.0774 - accuracy: 0.9733 - val_loss: 0.3551 - val_accuracy: 0.9024 - lr: 4.0252e-06\n",
      "Epoch 418/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0684 - accuracy: 0.9667\n",
      "Epoch 418: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.0684 - accuracy: 0.9667 - val_loss: 0.3991 - val_accuracy: 0.8935 - lr: 4.0252e-06\n",
      "Epoch 419/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1330 - accuracy: 0.9733\n",
      "Epoch 419: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.1330 - accuracy: 0.9733 - val_loss: 0.3971 - val_accuracy: 0.8849 - lr: 4.0252e-06\n",
      "Epoch 420/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0850 - accuracy: 0.9733\n",
      "Epoch 420: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.0850 - accuracy: 0.9733 - val_loss: 0.3710 - val_accuracy: 0.9011 - lr: 4.0252e-06\n",
      "Epoch 421/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0421 - accuracy: 0.9800\n",
      "Epoch 421: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.0421 - accuracy: 0.9800 - val_loss: 0.3902 - val_accuracy: 0.8947 - lr: 4.0252e-06\n",
      "Epoch 422/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1143 - accuracy: 0.9733\n",
      "Epoch 422: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.1143 - accuracy: 0.9733 - val_loss: 0.3886 - val_accuracy: 0.8913 - lr: 4.0252e-06\n",
      "Epoch 423/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1385 - accuracy: 0.9600\n",
      "Epoch 423: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.1385 - accuracy: 0.9600 - val_loss: 0.3418 - val_accuracy: 0.8988 - lr: 4.0252e-06\n",
      "Epoch 424/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0819 - accuracy: 0.9733\n",
      "Epoch 424: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.0819 - accuracy: 0.9733 - val_loss: 0.3541 - val_accuracy: 0.8992 - lr: 4.0252e-06\n",
      "Epoch 425/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1170 - accuracy: 0.9533\n",
      "Epoch 425: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.1170 - accuracy: 0.9533 - val_loss: 0.3638 - val_accuracy: 0.8966 - lr: 4.0252e-06\n",
      "Epoch 426/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1242 - accuracy: 0.9733\n",
      "Epoch 426: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.1242 - accuracy: 0.9733 - val_loss: 0.3946 - val_accuracy: 0.8895 - lr: 4.0252e-06\n",
      "Epoch 427/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0590 - accuracy: 0.9800\n",
      "Epoch 427: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.0590 - accuracy: 0.9800 - val_loss: 0.3974 - val_accuracy: 0.8913 - lr: 4.0252e-06\n",
      "Epoch 428/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0498 - accuracy: 0.9933\n",
      "Epoch 428: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.0498 - accuracy: 0.9933 - val_loss: 0.3868 - val_accuracy: 0.8923 - lr: 4.0252e-06\n",
      "Epoch 429/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0534 - accuracy: 0.9800\n",
      "Epoch 429: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.0534 - accuracy: 0.9800 - val_loss: 0.4182 - val_accuracy: 0.8949 - lr: 4.0252e-06\n",
      "Epoch 430/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0709 - accuracy: 0.9933\n",
      "Epoch 430: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.0709 - accuracy: 0.9933 - val_loss: 0.3617 - val_accuracy: 0.9018 - lr: 4.0252e-06\n",
      "Epoch 431/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0230 - accuracy: 1.0000\n",
      "Epoch 431: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.0230 - accuracy: 1.0000 - val_loss: 0.4101 - val_accuracy: 0.9002 - lr: 4.0252e-06\n",
      "Epoch 432/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0818 - accuracy: 0.9667\n",
      "Epoch 432: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.0818 - accuracy: 0.9667 - val_loss: 0.4352 - val_accuracy: 0.8898 - lr: 4.0252e-06\n",
      "Epoch 433/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1124 - accuracy: 0.9800\n",
      "Epoch 433: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.1124 - accuracy: 0.9800 - val_loss: 0.4873 - val_accuracy: 0.8899 - lr: 4.0252e-06\n",
      "Epoch 434/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1312 - accuracy: 0.9733\n",
      "Epoch 434: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.1312 - accuracy: 0.9733 - val_loss: 0.3667 - val_accuracy: 0.9045 - lr: 4.0252e-06\n",
      "Epoch 435/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0783 - accuracy: 0.9733\n",
      "Epoch 435: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.0783 - accuracy: 0.9733 - val_loss: 0.3431 - val_accuracy: 0.9039 - lr: 4.0252e-06\n",
      "Epoch 436/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0832 - accuracy: 0.9800\n",
      "Epoch 436: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.0832 - accuracy: 0.9800 - val_loss: 0.3653 - val_accuracy: 0.9091 - lr: 4.0252e-06\n",
      "Epoch 437/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1059 - accuracy: 0.9600\n",
      "Epoch 437: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.1059 - accuracy: 0.9600 - val_loss: 0.3815 - val_accuracy: 0.9055 - lr: 4.0252e-06\n",
      "Epoch 438/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0549 - accuracy: 0.9933\n",
      "Epoch 438: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.0549 - accuracy: 0.9933 - val_loss: 0.4075 - val_accuracy: 0.9026 - lr: 4.0252e-06\n",
      "Epoch 439/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0693 - accuracy: 0.9733\n",
      "Epoch 439: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.0693 - accuracy: 0.9733 - val_loss: 0.3820 - val_accuracy: 0.8991 - lr: 4.0252e-06\n",
      "Epoch 440/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0610 - accuracy: 0.9800\n",
      "Epoch 440: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.0610 - accuracy: 0.9800 - val_loss: 0.4085 - val_accuracy: 0.9004 - lr: 4.0252e-06\n",
      "Epoch 441/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0458 - accuracy: 0.9933\n",
      "Epoch 441: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.0458 - accuracy: 0.9933 - val_loss: 0.4454 - val_accuracy: 0.8886 - lr: 4.0252e-06\n",
      "Epoch 442/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1194 - accuracy: 0.9533\n",
      "Epoch 442: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.1194 - accuracy: 0.9533 - val_loss: 0.4123 - val_accuracy: 0.8872 - lr: 4.0252e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 443/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1164 - accuracy: 0.9533\n",
      "Epoch 443: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.1164 - accuracy: 0.9533 - val_loss: 0.4340 - val_accuracy: 0.8789 - lr: 4.0252e-06\n",
      "Epoch 444/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0456 - accuracy: 0.9933\n",
      "Epoch 444: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.0456 - accuracy: 0.9933 - val_loss: 0.3917 - val_accuracy: 0.8991 - lr: 4.0252e-06\n",
      "Epoch 445/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0796 - accuracy: 0.9600\n",
      "Epoch 445: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 792ms/step - loss: 0.0796 - accuracy: 0.9600 - val_loss: 0.3641 - val_accuracy: 0.8953 - lr: 4.0252e-06\n",
      "Epoch 446/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0503 - accuracy: 0.9667\n",
      "Epoch 446: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.0503 - accuracy: 0.9667 - val_loss: 0.3694 - val_accuracy: 0.9031 - lr: 4.0252e-06\n",
      "Epoch 447/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0383 - accuracy: 0.9867\n",
      "Epoch 447: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.0383 - accuracy: 0.9867 - val_loss: 0.4191 - val_accuracy: 0.8953 - lr: 4.0252e-06\n",
      "Epoch 448/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0668 - accuracy: 0.9800\n",
      "Epoch 448: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.0668 - accuracy: 0.9800 - val_loss: 0.4105 - val_accuracy: 0.8961 - lr: 4.0252e-06\n",
      "Epoch 449/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0612 - accuracy: 0.9933\n",
      "Epoch 449: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.0612 - accuracy: 0.9933 - val_loss: 0.4328 - val_accuracy: 0.8899 - lr: 4.0252e-06\n",
      "Epoch 450/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0902 - accuracy: 0.9667\n",
      "Epoch 450: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 797ms/step - loss: 0.0902 - accuracy: 0.9667 - val_loss: 0.4180 - val_accuracy: 0.8922 - lr: 4.0252e-06\n",
      "Epoch 451/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0796 - accuracy: 0.9867\n",
      "Epoch 451: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.0796 - accuracy: 0.9867 - val_loss: 0.4770 - val_accuracy: 0.8834 - lr: 4.0252e-06\n",
      "Epoch 452/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1275 - accuracy: 0.9667\n",
      "Epoch 452: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.1275 - accuracy: 0.9667 - val_loss: 0.4171 - val_accuracy: 0.8914 - lr: 4.0252e-06\n",
      "Epoch 453/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1117 - accuracy: 0.9667\n",
      "Epoch 453: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.1117 - accuracy: 0.9667 - val_loss: 0.3508 - val_accuracy: 0.9024 - lr: 4.0252e-06\n",
      "Epoch 454/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0409 - accuracy: 0.9800\n",
      "Epoch 454: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.0409 - accuracy: 0.9800 - val_loss: 0.3819 - val_accuracy: 0.8983 - lr: 4.0252e-06\n",
      "Epoch 455/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0617 - accuracy: 0.9733\n",
      "Epoch 455: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.0617 - accuracy: 0.9733 - val_loss: 0.4347 - val_accuracy: 0.8881 - lr: 4.0252e-06\n",
      "Epoch 456/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0781 - accuracy: 0.9667\n",
      "Epoch 456: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.0781 - accuracy: 0.9667 - val_loss: 0.4367 - val_accuracy: 0.8887 - lr: 4.0252e-06\n",
      "Epoch 457/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0701 - accuracy: 0.9600\n",
      "Epoch 457: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.0701 - accuracy: 0.9600 - val_loss: 0.4985 - val_accuracy: 0.8859 - lr: 4.0252e-06\n",
      "Epoch 458/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0184 - accuracy: 0.9933\n",
      "Epoch 458: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 797ms/step - loss: 0.0184 - accuracy: 0.9933 - val_loss: 0.5475 - val_accuracy: 0.8831 - lr: 4.0252e-06\n",
      "Epoch 459/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0397 - accuracy: 0.9866\n",
      "Epoch 459: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.0397 - accuracy: 0.9866 - val_loss: 0.4650 - val_accuracy: 0.8897 - lr: 4.0252e-06\n",
      "Epoch 460/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0820 - accuracy: 0.9533\n",
      "Epoch 460: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.0820 - accuracy: 0.9533 - val_loss: 0.6617 - val_accuracy: 0.8726 - lr: 4.0252e-06\n",
      "Epoch 461/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0736 - accuracy: 0.9867\n",
      "Epoch 461: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.0736 - accuracy: 0.9867 - val_loss: 0.5438 - val_accuracy: 0.8686 - lr: 4.0252e-06\n",
      "Epoch 462/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1259 - accuracy: 0.9467\n",
      "Epoch 462: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.1259 - accuracy: 0.9467 - val_loss: 0.4359 - val_accuracy: 0.8911 - lr: 4.0252e-06\n",
      "Epoch 463/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0894 - accuracy: 0.9533\n",
      "Epoch 463: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.0894 - accuracy: 0.9533 - val_loss: 0.5811 - val_accuracy: 0.8796 - lr: 4.0252e-06\n",
      "Epoch 464/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0545 - accuracy: 0.9733\n",
      "Epoch 464: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 797ms/step - loss: 0.0545 - accuracy: 0.9733 - val_loss: 0.3958 - val_accuracy: 0.8957 - lr: 4.0252e-06\n",
      "Epoch 465/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0933 - accuracy: 0.9800\n",
      "Epoch 465: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.0933 - accuracy: 0.9800 - val_loss: 0.4052 - val_accuracy: 0.8943 - lr: 4.0252e-06\n",
      "Epoch 466/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0695 - accuracy: 0.9600\n",
      "Epoch 466: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.0695 - accuracy: 0.9600 - val_loss: 0.3858 - val_accuracy: 0.8982 - lr: 4.0252e-06\n",
      "Epoch 467/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0531 - accuracy: 0.9933\n",
      "Epoch 467: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.0531 - accuracy: 0.9933 - val_loss: 0.4062 - val_accuracy: 0.8969 - lr: 4.0252e-06\n",
      "Epoch 468/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0269 - accuracy: 0.9933\n",
      "Epoch 468: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.0269 - accuracy: 0.9933 - val_loss: 0.4288 - val_accuracy: 0.9018 - lr: 4.0252e-06\n",
      "Epoch 469/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1068 - accuracy: 0.9667\n",
      "Epoch 469: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.1068 - accuracy: 0.9667 - val_loss: 0.3920 - val_accuracy: 0.9022 - lr: 4.0252e-06\n",
      "Epoch 470/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0477 - accuracy: 0.9867\n",
      "Epoch 470: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.0477 - accuracy: 0.9867 - val_loss: 0.3752 - val_accuracy: 0.9038 - lr: 4.0252e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 471/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0347 - accuracy: 0.9867\n",
      "Epoch 471: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.0347 - accuracy: 0.9867 - val_loss: 0.4083 - val_accuracy: 0.8973 - lr: 4.0252e-06\n",
      "Epoch 472/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0399 - accuracy: 0.9867\n",
      "Epoch 472: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.0399 - accuracy: 0.9867 - val_loss: 0.4319 - val_accuracy: 0.8947 - lr: 4.0252e-06\n",
      "Epoch 473/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1156 - accuracy: 0.9600\n",
      "Epoch 473: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.1156 - accuracy: 0.9600 - val_loss: 0.3928 - val_accuracy: 0.8931 - lr: 4.0252e-06\n",
      "Epoch 474/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1020 - accuracy: 0.9733\n",
      "Epoch 474: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.1020 - accuracy: 0.9733 - val_loss: 0.4973 - val_accuracy: 0.8847 - lr: 4.0252e-06\n",
      "Epoch 475/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0759 - accuracy: 0.9667\n",
      "Epoch 475: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.0759 - accuracy: 0.9667 - val_loss: 0.3956 - val_accuracy: 0.8952 - lr: 4.0252e-06\n",
      "Epoch 476/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0873 - accuracy: 0.9733\n",
      "Epoch 476: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.0873 - accuracy: 0.9733 - val_loss: 0.4085 - val_accuracy: 0.8865 - lr: 4.0252e-06\n",
      "Epoch 477/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1253 - accuracy: 0.9533\n",
      "Epoch 477: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.1253 - accuracy: 0.9533 - val_loss: 0.4458 - val_accuracy: 0.8775 - lr: 4.0252e-06\n",
      "Epoch 478/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0435 - accuracy: 0.9867\n",
      "Epoch 478: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.0435 - accuracy: 0.9867 - val_loss: 0.4607 - val_accuracy: 0.8882 - lr: 4.0252e-06\n",
      "Epoch 479/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0541 - accuracy: 0.9733\n",
      "Epoch 479: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.0541 - accuracy: 0.9733 - val_loss: 0.4019 - val_accuracy: 0.9029 - lr: 4.0252e-06\n",
      "Epoch 480/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0806 - accuracy: 0.9667\n",
      "Epoch 480: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.0806 - accuracy: 0.9667 - val_loss: 0.4363 - val_accuracy: 0.9009 - lr: 4.0252e-06\n",
      "Epoch 481/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1059 - accuracy: 0.9667\n",
      "Epoch 481: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.1059 - accuracy: 0.9667 - val_loss: 0.4498 - val_accuracy: 0.8803 - lr: 4.0252e-06\n",
      "Epoch 482/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0418 - accuracy: 0.9800\n",
      "Epoch 482: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.0418 - accuracy: 0.9800 - val_loss: 0.5357 - val_accuracy: 0.8737 - lr: 4.0252e-06\n",
      "Epoch 483/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0402 - accuracy: 0.9867\n",
      "Epoch 483: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.0402 - accuracy: 0.9867 - val_loss: 0.4153 - val_accuracy: 0.9024 - lr: 4.0252e-06\n",
      "Epoch 484/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0198 - accuracy: 0.9933\n",
      "Epoch 484: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.0198 - accuracy: 0.9933 - val_loss: 0.4827 - val_accuracy: 0.8940 - lr: 4.0252e-06\n",
      "Epoch 485/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1300 - accuracy: 0.9533\n",
      "Epoch 485: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.1300 - accuracy: 0.9533 - val_loss: 0.6437 - val_accuracy: 0.8413 - lr: 4.0252e-06\n",
      "Epoch 486/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1038 - accuracy: 0.9533\n",
      "Epoch 486: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.1038 - accuracy: 0.9533 - val_loss: 0.3610 - val_accuracy: 0.9029 - lr: 4.0252e-06\n",
      "Epoch 487/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1644 - accuracy: 0.9533\n",
      "Epoch 487: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.1644 - accuracy: 0.9533 - val_loss: 0.4718 - val_accuracy: 0.8946 - lr: 4.0252e-06\n",
      "Epoch 488/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0794 - accuracy: 0.9800\n",
      "Epoch 488: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 797ms/step - loss: 0.0794 - accuracy: 0.9800 - val_loss: 0.3746 - val_accuracy: 0.8964 - lr: 4.0252e-06\n",
      "Epoch 489/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0474 - accuracy: 0.9867\n",
      "Epoch 489: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 793ms/step - loss: 0.0474 - accuracy: 0.9867 - val_loss: 0.4413 - val_accuracy: 0.8973 - lr: 4.0252e-06\n",
      "Epoch 490/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1214 - accuracy: 0.9667\n",
      "Epoch 490: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 797ms/step - loss: 0.1214 - accuracy: 0.9667 - val_loss: 0.3707 - val_accuracy: 0.8969 - lr: 4.0252e-06\n",
      "Epoch 491/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0498 - accuracy: 0.9867\n",
      "Epoch 491: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 794ms/step - loss: 0.0498 - accuracy: 0.9867 - val_loss: 0.3641 - val_accuracy: 0.9023 - lr: 4.0252e-06\n",
      "Epoch 492/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1115 - accuracy: 0.9667\n",
      "Epoch 492: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.1115 - accuracy: 0.9667 - val_loss: 0.3910 - val_accuracy: 0.8938 - lr: 4.0252e-06\n",
      "Epoch 493/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0295 - accuracy: 0.9867\n",
      "Epoch 493: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.0295 - accuracy: 0.9867 - val_loss: 0.4214 - val_accuracy: 0.9014 - lr: 4.0252e-06\n",
      "Epoch 494/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.1266 - accuracy: 0.9667\n",
      "Epoch 494: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 797ms/step - loss: 0.1266 - accuracy: 0.9667 - val_loss: 0.5908 - val_accuracy: 0.8535 - lr: 4.0252e-06\n",
      "Epoch 495/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0560 - accuracy: 0.9800\n",
      "Epoch 495: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.0560 - accuracy: 0.9800 - val_loss: 0.4107 - val_accuracy: 0.8961 - lr: 4.0252e-06\n",
      "Epoch 496/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0279 - accuracy: 0.9867\n",
      "Epoch 496: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 797ms/step - loss: 0.0279 - accuracy: 0.9867 - val_loss: 0.4569 - val_accuracy: 0.8957 - lr: 4.0252e-06\n",
      "Epoch 497/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0848 - accuracy: 0.9667\n",
      "Epoch 497: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.0848 - accuracy: 0.9667 - val_loss: 0.4785 - val_accuracy: 0.8933 - lr: 4.0252e-06\n",
      "Epoch 498/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0264 - accuracy: 0.9933\n",
      "Epoch 498: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.0264 - accuracy: 0.9933 - val_loss: 0.4444 - val_accuracy: 0.8873 - lr: 4.0252e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0699 - accuracy: 0.9800\n",
      "Epoch 499: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 795ms/step - loss: 0.0699 - accuracy: 0.9800 - val_loss: 0.4415 - val_accuracy: 0.8928 - lr: 4.0252e-06\n",
      "Epoch 500/500\n",
      "75/75 [==============================] - ETA: 0s - loss: 0.0699 - accuracy: 0.9800\n",
      "Epoch 500: val_loss did not improve from 0.32161\n",
      "75/75 [==============================] - 59s 796ms/step - loss: 0.0699 - accuracy: 0.9800 - val_loss: 0.4236 - val_accuracy: 0.8985 - lr: 4.0252e-06\n"
     ]
    }
   ],
   "source": [
    "results = model.fit(train_generator,\n",
    "                    steps_per_epoch=75,\n",
    "                    epochs=500,  # Number of epochs\n",
    "                    validation_data=val_generator,\n",
    "                    #                                         validation_steps=50,\n",
    "                    verbose=1,\n",
    "                    callbacks=[\n",
    "                        lr_schd_cb,\n",
    "                        csv_logger,\n",
    "                        #                         early_stop,\n",
    "                        best_model\n",
    "                    ]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b08e3766",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T07:58:11.498532Z",
     "start_time": "2022-05-29T07:58:11.216743Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_model_trainTestGraphs(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3207bd1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T16:14:48.932744Z",
     "start_time": "2022-05-29T16:14:48.220436Z"
    }
   },
   "outputs": [],
   "source": [
    "m = models.load_model('tf_TransferLearning_8Classes_best_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d6394350",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T16:15:47.238721Z",
     "start_time": "2022-05-29T16:14:49.655757Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1418/1418 [==============================] - 58s 40ms/step - loss: 0.3216 - accuracy: 0.9101\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.32161274552345276, 0.9100528955459595]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7275bd63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T16:16:01.584931Z",
     "start_time": "2022-05-29T16:15:47.381753Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1793/1793 [==============================] - 14s 8ms/step - loss: 0.3871 - accuracy: 0.9236\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3870948553085327, 0.9235917329788208]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4195aa4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T07:59:24.935529Z",
     "start_time": "2022-05-29T07:59:24.923525Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bright dune': 0,\n",
       " 'crater': 1,\n",
       " 'dark dune': 2,\n",
       " 'impact ejecta': 3,\n",
       " 'other': 4,\n",
       " 'slope streak': 5,\n",
       " 'spider': 6,\n",
       " 'swiss cheese': 7}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313b2f21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfGPU",
   "language": "python",
   "name": "tfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "667.852px",
    "left": "1580px",
    "right": "20px",
    "top": "120px",
    "width": "800px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
